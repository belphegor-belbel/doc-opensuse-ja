# translation of tuning_cgroups.xml.po to Japanese
# Japanese translations for PACKAGE package
# PACKAGE パッケージに対する英訳.
#
# Automatically generated, 2018.
# Yasuhiko Kamata <belphegor@belbel.or.jp>, 2019, 2020, 2021.
msgid ""
msgstr ""
"Project-Id-Version: tuning_cgroups.xml\n"
"Report-Msgid-Bugs-To: https://github.com/belphegor-belbel/doc-opensuse-ja\n"
"POT-Creation-Date: 2021-11-17 22:04+0000\n"
"PO-Revision-Date: 2021-11-18 07:38+0900\n"
"Last-Translator: Yasuhiko Kamata <belphegor@belbel.or.jp>\n"
"Language-Team: Japanese <opensuse-ja@opensuse.org>\n"
"Language: ja\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: KBabel 1.11.4\n"

#. Tag: title
#: tuning_cgroups.xml:22
#, no-c-format
msgid "Kernel control groups"
msgstr "カーネルコントロールグループ"

#. Tag: para
#: tuning_cgroups.xml:25
#, no-c-format
msgid ""
"Kernel Control Groups ( <quote>cgroups</quote> ) are a kernel feature that "
"allows assigning and limiting hardware and system resources for processes. "
"Processes can also be organized in a hierarchical tree structure."
msgstr ""
"カーネルコントロールグループ ( <quote>cgroups</quote> ) は、プロセスに対して"
"ハードウエアやシステムの資源を割り当てたり、制限したりするための仕組みです。"
"この機能を利用することで、プロセスをツリー構造で管理することができるようにな"
"ります。"

#. Tag: title
#: tuning_cgroups.xml:38
#, no-c-format
msgid "Overview"
msgstr "概要"

#. Tag: para
#: tuning_cgroups.xml:39
#, no-c-format
msgid ""
"Every process is assigned exactly one administrative cgroup. cgroups are "
"ordered in a hierarchical tree structure. You can set resource limitations, "
"such as CPU, memory, disk I/O, or network bandwidth usage, for single "
"processes or for whole branches of the hierarchy tree."
msgstr ""
"それぞれのプロセスは正確に 1 つの管理用 cgroup に割り当てられます。 cgroup は"
"階層構造型のツリー (木構造) として管理するもので、その構造の任意の箇所 (枝) "
"もしくは 1 つのプロセスに対して、 CPU やメモリ、ディスクの I/O やネットワーク"
"帯域などのリソース制限を割り当てます。"

#. Tag: para
#: tuning_cgroups.xml:45
#, no-c-format
msgid ""
"On &productname;, &systemd; uses cgroups to organize all processes in "
"groups, which &systemd; calls slices. &systemd; also provides an interface "
"for setting cgroup properties."
msgstr ""
"&productname; では、 &systemd; が cgroup を利用してグループ内の全てのプロセス"
"を管理しています。この場合、 &systemd; はグループをスライスと呼んでいます。 "
"&systemd; には、 cgroup の設定を行うためのインターフェイスも用意されていま"
"す。"

#. Tag: para
#: tuning_cgroups.xml:50
#, no-c-format
msgid "The command <command>systemd-cgls</command> displays the hierarchy tree."
msgstr ""
"<command>systemd-cgls</command> コマンドでは、階層構造を表示することができま"
"す。"

#. Tag: para
#: tuning_cgroups.xml:54
#, no-c-format
msgid ""
"There are two versions of cgroup APIs provided by the kernel. These differ "
"in the cgroup attributes they provide, and in the organization of controller "
"hierarchies. &systemd; attempts to abstract the differences away. By default "
"&systemd; runs in the <emphasis>hybrid</emphasis> mode, which means "
"controllers are used through the v1 API. cgroup v2 is only used for "
"systemd's own tracking. There is also the <emphasis>unified</emphasis> mode "
"when the controllers are used though v2 API. The mode in which controllers "
"is exclusive."
msgstr ""
"カーネルが提供する cgroup の API には 2 種類のものが存在します。これらは提供する"
" cgroup 属性が異なるほか、コントローラの階層構造が異なります。 &systemd; は抽象化"
"の仕組みによって、これらの違いを吸収しています。既定では &systemd; は <emphasis>"
"ハイブリッド</emphasis> モードで動作し、 v1 API を利用してコントローラを制御します。"
" cgroup v2 は systemd 内でのみ使用されます。このほか <emphasis>統合</emphasis> "
"モードとして、コントローラを v2 API で制御するモードもあります。モードはいずれか"
"一方のみを排他的に使用することができます。"

#. Tag: para
#: tuning_cgroups.xml:64
#, no-c-format
msgid ""
"To enable the unified control group hierarchy, append <option>systemd."
"unified_cgroup_hierarchy=1</option> as a kernel command line parameter to "
"the &grub; boot loader. (Refer to <xref linkend=\"cha-grub2\"/> for more "
"details about configuring &grub;.)"
msgstr ""
"統合型のコントロールグループ階層構造を有効化したい場合は、 &grub; ブートローダ"
"の設定で、カーネルのコマンドラインパラメータに <option>systemd."
"unified_cgroup_hierarchy=1</option> を追加してください (&grub; の設定方法に"
"関する詳細は、 <xref linkend=\"cha-grub2\"/> をお読みください) 。"

#. Tag: title
#: tuning_cgroups.xml:73
#, no-c-format
msgid "Resource accounting"
msgstr "リソースアカウンティング"

#. Tag: para
#: tuning_cgroups.xml:74
#, no-c-format
msgid ""
"The placement of processes into different cgroups can be used to obtain per-"
"cgroup information of certain resource consumption."
msgstr ""
"複数の cgroup にプロセスを別々に配置することで、 cgroup ごとのリソース消費量"
"の情報を取得できるようになります。"

#. Tag: para
#: tuning_cgroups.xml:78
#, no-c-format
msgid ""
"The accounting has relatively small but non-zero overhead, whose impact "
"depends on the workload. Be aware that turning on accounting for one unit "
"will also implicitly turn it on for all units directly contained in the same "
"slice and for all its parent slices and the units directly contained "
"therein. Therefore the accounting cost is not exclusive to the single unit."
msgstr ""
"このような機能をアカウンティングと呼びますが、この機能自身にも小さいながら"
"オーバーヘッドが存在しています。このオーバーヘッドはその中での処理内容にも依"
"存しますが、特定の 1 つのユニットに対してアカウンティングを有効にすると、同じ"
"スライスに含まれる全てのユニットだけでなく、親スライスやそこに直接含まれるユ"
"ニットに対しても、機能が有効化されることに注意してください。そのため、アカウ"
"ンティングによる負荷は 1 つのユニットだけにとどまらないことになります。"

#. Tag: para
#: tuning_cgroups.xml:86
#, no-c-format
msgid ""
"The accounting can be set on a per-unit basis with directives such as "
"<literal>MemoryAccounting=</literal> or globally for all units in <filename>/"
"etc/systemd/system.conf</filename> with the directive "
"<literal>DefaultMemoryAccounting=</literal> . Refer to <literal>systemd."
"resource-control (5)</literal> for the exhaustive list of possible "
"directives."
msgstr ""
"ユニット単位でアカウンティングを有効化したい場合は "
"<literal>MemoryAccounting=</literal> のようなディレクティブを使用することがで"
"きます。全てのユニットに対して有効化したい場合は、 <filename>/etc/systemd/"
"system.conf</filename> ファイル内の <literal>DefaultMemoryAccounting=</"
"literal> を設定してください。設定可能なディレクティブに関する詳細は、 "
"<literal>systemd.resource-control (5)</literal> をお読みください。"

#. Tag: title
#: tuning_cgroups.xml:97
#, no-c-format
msgid "Setting resource limits"
msgstr "リソース制限の設定"

#. Tag: title
#: tuning_cgroups.xml:99
#, no-c-format
msgid "Implicit resource consumption"
msgstr "暗黙のリソース消費について"

#. Tag: para
#: tuning_cgroups.xml:100
#, no-c-format
msgid ""
"Be aware that resource consumption implicitly depends on the environment "
"where your workload executes (for example, size of data structures in "
"libraries/kernel, forking behavior of utilities, computational efficiency). "
"Hence it is recommended to (re)calibrate your limits should the environment "
"change."
msgstr ""
"暗黙のうちに消費され、実行環境によって異なるリソースが存在することに注意して"
"ください。これにはたとえば、ライブラリやカーネル内のデータ構造のほか、利用し"
"ているユーティリティの fork() 処理の振る舞い、計算の効率性などがあります。こ"
"のようなことから、実行環境を変えた場合は、リソース制限を再計算する必要があり"
"ます。"

#. Tag: para
#: tuning_cgroups.xml:107
#, no-c-format
msgid ""
"Limitations to <literal>cgroups</literal> can be set with the "
"<command>systemctl set-property</command> command. The syntax is:"
msgstr ""
"<literal>cgroup</literal> に対する制限は、 <command>systemctl set-property</"
"command> コマンドで設定します。書式は下記のとおりです:"

#. Tag: screen
#: tuning_cgroups.xml:111
#, no-c-format
msgid ""
"&prompt.root;<command>systemctl set-property [--runtime] <replaceable>NAME</"
"replaceable> <replaceable>PROPERTY1</replaceable>=<replaceable>VALUE</"
"replaceable> [<replaceable>PROPERTY2</replaceable>=<replaceable>VALUE</"
"replaceable>]</command>"
msgstr ""
"&prompt.root;<command>systemctl set-property [--runtime] <replaceable>名前</"
"replaceable> <replaceable>プロパティ_1</replaceable>=<replaceable>値</"
"replaceable> [<replaceable>プロパティ_2</replaceable>=<replaceable>値</"
"replaceable>]</command>"

#. Tag: para
#: tuning_cgroups.xml:112
#, no-c-format
msgid ""
"The configured value is applied immediately. Optionally, use the <option>--"
"runtime</option> option. With this option, set values do not persist after "
"the next reboot."
msgstr ""
"設定値は即時に適用されます。なお、必要であれば <option>--runtime</option> オプションを"
"指定することもできます。このオプションを指定すると、再起動後には指定した制限が"
"適用されなくなります。"

#. Tag: para
#: tuning_cgroups.xml:117
#, no-c-format
msgid ""
"Replace <replaceable>NAME</replaceable> with a &systemd; service, scope or "
"slice name."
msgstr ""
"また、 <replaceable>名前</replaceable> には &systemd; のサービス名やスコープ"
"名、もしくはスライス名を指定します。"

#. Tag: para
#: tuning_cgroups.xml:120
#, no-c-format
msgid ""
"For a complete list of properties and more details, see <command>man systemd."
"resource-control</command> ."
msgstr ""
"プロパティの一覧と詳細については、 <command>man systemd.resource-"
"control</command> で表示されるマニュアルページをお読みください。"

#. Tag: title
#: tuning_cgroups.xml:127
#, no-c-format
msgid "Preventing fork bombs with <literal>TasksMax</literal>"
msgstr "<literal>TasksMax</literal> を利用した fork ボムの防止"

#. Tag: para
#: tuning_cgroups.xml:128
#, no-c-format
msgid ""
"&systemd; allows configuring task count limits both for each individual leaf "
"unit or aggregated on slices (mainly `user-$UID.slice`). Upstream &systemd; "
"ships with defaults that limit the number of tasks in each unit (15% of the "
"kernel global limit, see <command>cat /proc/sys/kernel/pid_max</command> ). "
"Each user's slice is limited to 33% of the kernel limit."
msgstr ""
"&systemd; では、ユニットごとやスライスごと (主に `user-$UID.slice`) にタスク数"
"の制限を設定することができます。 &systemd; の提供元では、ユニットごとのタスク数"
"制限の既定値を、 カーネル全体での制限 (詳しくは <command>cat /proc/sys/kernel/"
"pid_max</command> を参照) に対して 15% に設定しています。各ユーザのスライスは"
"カーネル全体での制限の 33% になっています。"

#. Tag: title
#: tuning_cgroups.xml:137
#, no-c-format
msgid "Finding the current default <literal>TasksMax</literal> values"
msgstr "現時点での既定の <literal>TasksMax</literal> 値の検出"

#. Tag: para
#: tuning_cgroups.xml:138
#, no-c-format
msgid ""
"However, it became apparent in practice that there is not a single default "
"that applies to all use cases. &productname; ships with two custom "
"configurations that override the upstream defaults for system units and for "
"user slices, and sets them both to <literal>infinity</literal> . <filename>/"
"usr/lib/systemd/system.conf.d/20-suse-defaults.conf</filename> contains "
"these lines:"
msgstr ""
"しかしながら、全ての用途に対して単一の制限を適用するのは現実的ではありません。"
" &productname; では、システムユニットやユーザスライスに対する提供元の既定値"
"を上書きするための独自設定ファイルが 2 つ用意され、いずれも <literal>infinity"
"</literal> に設定されています。 <filename>/usr/lib/systemd/system.conf.d/"
"20-suse-defaults.conf</filename> には、下記のような設定が書かれています:"

#. Tag: screen
#: tuning_cgroups.xml:147
#, no-c-format
msgid ""
"\n"
"[Manager]\n"
"DefaultTasksMax=infinity\n"
msgstr ""
"\n"
"[Manager]\n"
"DefaultTasksMax=infinity\n"

#. Tag: para
#: tuning_cgroups.xml:151
#, no-c-format
msgid ""
"<filename>/usr/lib/systemd/system/user-.slice.d/20-suse-defaults.conf</"
"filename> contains these lines:"
msgstr ""
"もう 1 つの存在である <filename>/usr/lib/systemd/system/user-.slice.d/20-"
"suse-defaults.conf</filename> には、下記のような設定が書かれています:"

#. Tag: screen
#: tuning_cgroups.xml:155
#, no-c-format
msgid ""
"[Slice]\n"
"TasksMax=infinity\n"
msgstr ""
"[Slice]\n"
"TasksMax=infinity\n"

#. Tag: para
#: tuning_cgroups.xml:158
#, no-c-format
msgid ""
"<literal>infinity</literal> means having no limit. It is not a requirement "
"to change the default, but setting some limits may help to prevent system "
"crashes from runaway processes."
msgstr ""
"<literal>infinity</literal> は無制限の意味です。特に要件がなければ既定値を変"
"更する必要はありませんが、必要であれば設定を変更してください。"

#. Tag: title
#: tuning_cgroups.xml:166
#, no-c-format
msgid "Overriding the <literal>DefaultTasksMax</literal> value"
msgstr "<literal>DefaultTasksMax</literal> 値の設定"

#. Tag: para
#: tuning_cgroups.xml:167
#, no-c-format
msgid ""
"Change the global <literal>DefaultTasksMax</literal> value by creating a new "
"override file, <filename>/etc/systemd/system.conf.d/90-system-tasksmax.conf</"
"filename> , and write the following lines to set a new default limit of 256 "
"tasks per system unit:"
msgstr ""
"グローバルな <literal>DefaultTasksMax</literal> の値を変更したい場合は、設定"
"を上書きするための新しい設定ファイル <filename>/etc/systemd/system.conf.d/90-"
"system-tasksmax.conf</filename> を作成して対応してください。この設定ファイル"
"には、下記のような内容を記述します (下記の例では、 systemd のユニットごとに最"
"大 256 個までのタスク制限を設定します):"

#. Tag: screen
#: tuning_cgroups.xml:174
#, no-c-format
msgid ""
"\n"
"[Manager]\n"
"DefaultTasksMax=256\n"
msgstr ""
"\n"
"[Manager]\n"
"DefaultTasksMax=256\n"

#. Tag: para
#: tuning_cgroups.xml:178
#, no-c-format
msgid "Load the new setting, then verify that it changed:"
msgstr "新しい設定を読み込んで、設定が反映されたことを確認します:"

#. Tag: screen
#: tuning_cgroups.xml:181
#, no-c-format
msgid ""
"&prompt.sudo;systemctl daemon-reload\n"
"&prompt.user;systemctl show --property DefaultTasksMax\n"
"DefaultTasksMax=256\n"
msgstr ""
"&prompt.sudo;systemctl daemon-reload\n"
"&prompt.user;systemctl show --property DefaultTasksMax\n"
"DefaultTasksMax=256\n"

#. Tag: para
#: tuning_cgroups.xml:185
#, no-c-format
msgid ""
"Adjust this default value to suit your needs. You can set different limits "
"on individual services as needed. This example is for MariaDB. First check "
"the current active value:"
msgstr ""
"設定値はお使いのシステムの要件に合わせて指定してください。また、特定のサービ"
"スに限定して制限を高くすることもできます。たとえば MariaDB で設定を変更したい"
"場合、まずは現在の設定値を確認します:"

#. Tag: screen
#: tuning_cgroups.xml:190
#, no-c-format
msgid ""
"\n"
"&prompt.user;systemctl status mariadb.service\n"
"  ● mariadb.service - MariaDB database server\n"
"   Loaded: loaded (/usr/lib/systemd/system/mariadb.service; disabled; vendor "
"preset&gt;\n"
"   Active: active (running) since Tue 2020-05-26 14:15:03 PDT; 27min ago\n"
"     Docs: man:mysqld(8)\n"
"           https://mariadb.com/kb/en/library/systemd/\n"
" Main PID: 11845 (mysqld)\n"
"   Status: \"Taking your SQL requests now...\"\n"
"    Tasks: 30 (limit: 256)\n"
"   CGroup: /system.slice/mariadb.service\n"
"           └─11845 /usr/sbin/mysqld --defaults-file=/etc/my.cnf --"
"user=mysql\n"
msgstr ""
"\n"
"&prompt.user;systemctl status mariadb.service\n"
"  ● mariadb.service - MariaDB database server\n"
"   Loaded: loaded (/usr/lib/systemd/system/mariadb.service; disabled; vendor "
"preset&gt;\n"
"   Active: active (running) since Tue 2020-05-26 14:15:03 PDT; 27min ago\n"
"     Docs: man:mysqld(8)\n"
"           https://mariadb.com/kb/en/library/systemd/\n"
" Main PID: 11845 (mysqld)\n"
"   Status: \"Taking your SQL requests now...\"\n"
"    Tasks: 30 (limit: 256)\n"
"   CGroup: /system.slice/mariadb.service\n"
"           └─11845 /usr/sbin/mysqld --defaults-file=/etc/my.cnf --"
"user=mysql\n"

#. Tag: para
#: tuning_cgroups.xml:203
#, no-c-format
msgid ""
"The Tasks line shows that MariaDB currently has 30 tasks running, and has an "
"upper limit of the default 256, which is inadequate for a database. The "
"following example demonstrates how to raise MariaDB's limit to 8192."
msgstr ""
"Tasks 以下には現在動作中のタスク数 (30 個) と上限 (256 個) が示されています。負荷の"
"高いデータベースシステムとしては不十分な値であることから、たとえば MariaDB のみを"
" 8192 個までに拡大してみることにします。"

#. Tag: screen
#: tuning_cgroups.xml:208
#, no-c-format
msgid ""
"&prompt.sudo;systemctl set-property mariadb.service TasksMax=8192\n"
"&prompt.user;systemctl status mariadb.service \n"
"● mariadb.service - MariaDB database server\n"
"   Loaded: loaded (/usr/lib/systemd/system/mariadb.service; disabled; vendor "
"preset: disab&gt;\n"
"  Drop-In: /etc/systemd/system/mariadb.service.d\n"
"           └─50-TasksMax.conf\n"
"   Active: active (running) since Tue 2020-06-02 17:57:48 PDT; 7min ago\n"
"     Docs: man:mysqld(8)\n"
"           https://mariadb.com/kb/en/library/systemd/\n"
"  Process: 3446 ExecStartPre=/usr/lib/mysql/mysql-systemd-helper upgrade "
"(code=exited, sta&gt;\n"
"  Process: 3440 ExecStartPre=/usr/lib/mysql/mysql-systemd-helper install "
"(code=exited, sta&gt;\n"
" Main PID: 3452 (mysqld)\n"
"   Status: \"Taking your SQL requests now...\"\n"
"    Tasks: 30 (limit: 8192)\n"
"   CGroup: /system.slice/mariadb.service\n"
"           └─3452 /usr/sbin/mysqld --defaults-file=/etc/my.cnf --user=mysql\n"
msgstr ""
"&prompt.sudo;systemctl set-property mariadb.service TasksMax=8192\n"
"&prompt.user;systemctl status mariadb.service \n"
"● mariadb.service - MariaDB database server\n"
"   Loaded: loaded (/usr/lib/systemd/system/mariadb.service; disabled; vendor "
"preset: disab&gt;\n"
"  Drop-In: /etc/systemd/system/mariadb.service.d\n"
"           └─50-TasksMax.conf\n"
"   Active: active (running) since Tue 2020-06-02 17:57:48 PDT; 7min ago\n"
"     Docs: man:mysqld(8)\n"
"           https://mariadb.com/kb/en/library/systemd/\n"
"  Process: 3446 ExecStartPre=/usr/lib/mysql/mysql-systemd-helper upgrade "
"(code=exited, sta&gt;\n"
"  Process: 3440 ExecStartPre=/usr/lib/mysql/mysql-systemd-helper install "
"(code=exited, sta&gt;\n"
" Main PID: 3452 (mysqld)\n"
"   Status: \"Taking your SQL requests now...\"\n"
"    Tasks: 30 (limit: 8192)\n"
"   CGroup: /system.slice/mariadb.service\n"
"           └─3452 /usr/sbin/mysqld --defaults-file=/etc/my.cnf --user=mysql\n"

#. Tag: para
#: tuning_cgroups.xml:225
#, no-c-format
msgid ""
"<command>systemctl set-property</command> applies the new limit and creates "
"a drop-in file for persistence, <filename>/etc/systemd/system/mariadb."
"service.d/50-TasksMax.conf</filename> , that contains only the changes you "
"want to apply to the existing unit file. The value does not have to be 8192, "
"but should be whatever limit is appropriate for your workloads."
msgstr ""
"<command>systemctl set-property</command> コマンドは、 <filename>/etc/systemd/"
"system/mariadb.service.d/50-TasksMax.conf</filename> という名前の上書き用設定"
"ファイルを作成して、新しい制限を設定します。ここには既存のユニットファイルに対する"
"上書き値のみを保存します。もちろん 8192 でなくてもかまいません。お使いのシステムの"
"負荷状況に合わせて設定してください。"

#. Tag: title
#: tuning_cgroups.xml:236
#, no-c-format
msgid "Default <literal>TasksMax</literal> limit on users"
msgstr "ユーザに対する既定の <literal>TasksMax</literal> 制限"

#. Tag: para
#: tuning_cgroups.xml:237
#, no-c-format
msgid ""
"The default limit on users should be fairly high, because user sessions need "
"more resources. Set your own default for any user by creating a new file, "
"for example <filename>/etc/systemd/system/user-.slice.d/40-user-taskmask."
"conf</filename> . The following example sets a default of 16284:"
msgstr ""
"ユーザに対する既定の制限値は十分に高く設定されています。これは、ユーザセッ"
"ションではより多くのリソースを必要とするためです。独自の制限を設定したい場合"
"は、 <filename>/etc/systemd/system/user-.slice.d/40-user-taskmask."
"conf</filename> のような設定ファイルを作成し、その中に設定値を記述してください。"
"下記の例では、タスクの最大値を 16284 に設定しています:"

#. Tag: screen
#: tuning_cgroups.xml:244
#, no-c-format
msgid ""
"\n"
"[Slice]\n"
"TasksMax=16284\n"
msgstr ""
"\n"
"[Slice]\n"
"TasksMax=16284\n"

#. Tag: title
#: tuning_cgroups.xml:249
#, no-c-format
msgid "Numeric prefixes reference"
msgstr "ファイル名の冒頭に付与する数値について"

#. Tag: para
#: tuning_cgroups.xml:250
#, no-c-format
msgid ""
"See <link xlink:href=\"https://documentation.suse.com/sles/15-SP3/html/SLES-"
"all/cha-systemd.html#sec-boot-systemd-custom-drop-in\"/> to learn what "
"numeric prefixes are expected for drop-in files."
msgstr ""
"上書き用の設定ファイルを作成する場合、そのファイル名の冒頭には数値を指定する必要があります。"
"その数値の設定方法に関する詳細は、 <link xlink:href=\"https://documentation.suse."
"com/sles/15-SP3/html/SLES-all/cha-systemd.html#sec-boot-systemd-custom-drop-in\"/> "
"をお読みください。"

#. Tag: para
#: tuning_cgroups.xml:256
#, no-c-format
msgid "Then reload systemd to load the new value, and verify the change:"
msgstr ""
"あとは systemd に対して設定値の再読み込みを指示し、設定が変更されたことを確認"
"します:"

#. Tag: screen
#: tuning_cgroups.xml:259
#, no-c-format
msgid ""
"&prompt.sudo;systemctl daemon-reload\n"
"\n"
"&prompt.user;systemctl show --property TasksMax user-1000.slice\n"
"TasksMax=16284\n"
msgstr ""
"&prompt.sudo;systemctl daemon-reload\n"
"\n"
"&prompt.user;systemctl show --property TasksMax user-1000.slice\n"
"TasksMax=16284\n"

#. Tag: para
#: tuning_cgroups.xml:264
#, no-c-format
msgid ""
"How do you know what values to use? This varies according to your workloads, "
"system resources, and other resource configurations. When your "
"<literal>TasksMax</literal> value is too low, you will see error messages "
"such as <emphasis>Failed to fork (Resources temporarily unavailable)</"
"emphasis> , <emphasis>Can't create thread to handle new connection</"
"emphasis> , and <emphasis>Error: Function call 'fork' failed with error code "
"11, 'Resource temporarily unavailable'</emphasis> ."
msgstr ""
"具体的にどのような設定値にすべきかについては、システムの用途と搭載されている"
"リソースのほか、他のリソース設定によっても異なります。 <literal>TasksMax</"
"literal> の値が少なすぎる場合は <emphasis>Failed to fork (Resources "
"temporarily unavailable)</emphasis> (fork に失敗した (リソースが一時的に利用"
"できなくなっている)) や <emphasis>Can't create thread to handle new "
"connection</emphasis> (新しい接続を処理するためのスレッドが作成できない), "
"<emphasis>Error: Function call 'fork' failed with error code 11, 'Resource "
"temporarily unavailable'</emphasis> (エラーコード 11 (リソースが一時的に利用"
"できなくなっている) で fork の関数呼び出しが失敗した) などのエラーが発生しま"
"す。"

#. Tag: para
#: tuning_cgroups.xml:274
#, no-c-format
msgid ""
"For more information on configuring system resources in systemd, see "
"<literal>systemd.resource-control (5)</literal> ."
msgstr ""
"systemd でのシステムリソースの制限の設定方法について、詳しくは"
"<literal>systemd.resource-control (5)</literal> をお読みください。"

#. Tag: title
#: tuning_cgroups.xml:282
#, no-c-format
msgid "Controlling I/O with proportional weight policy"
msgstr "比例型の重み付けポリシーによる I/O の制御"

#. Tag: para
#: tuning_cgroups.xml:283
#, no-c-format
msgid ""
"This section introduces using the Linux kernel's block I/O controller to "
"prioritize I/O operations. The cgroup blkio subsystem controls and monitors "
"access to I/O on block devices. State objects that contain the subsystem "
"parameters for a cgroup are represented as pseudo-files within the cgroup "
"virtual file system, also called a pseudo-file system."
msgstr ""
"本章では、 Linux カーネル内に存在する I/O コントローラを利用して、 I/O 処理の"
"優先付けを行うための方法について説明しています。 cgroup blkio サブシステムで"
"は、ブロックデバイスに対する I/O 処理を制御したり監視したりすることができるほ"
"か、 cgroup の仮想ファイルシステム (擬似ファイルシステムとも呼ばれます) 内の"
"ファイルとして、 cgroup 向けのサブシステムパラメータを含むステートオブジェク"
"トが提供されています。"

#. Tag: para
#: tuning_cgroups.xml:290
#, no-c-format
msgid ""
"The examples in this section show how writing values to some of these pseudo-"
"files limits access or bandwidth, and reading values from some of these "
"pseudo-files provides information on I/O operations. Examples are provided "
"for both cgroup-v1 and cgroup-v2."
msgstr ""
"本章では、アクセスや帯域を制限するための擬似ファイルへの書き込み方法のほか、 "
"I/O 処理の関する様々な情報を提供する擬似ファイルの読み込み方法を説明していま"
"す。また、 cgroup-v1 と cgroup-v2 の両方に対する例を示しています。"

#. Tag: para
#: tuning_cgroups.xml:296
#, no-c-format
msgid ""
"You need a test directory containing two files for testing performance and "
"changed settings. A quick way to create test files fully populated with text "
"is using the <command>yes</command> command. The following example commands "
"create a test directory, and then populate it with two 537 MB text files:"
msgstr ""
"まずはテスト用のディレクトリを作成し、その中にファイルを 2 つ作成して性能のテ"
"ストを行います。ある程度のサイズのファイルを作成するため、本章では "
"<command>yes</command> コマンドを使用します。下記の例ではテストディレクトリを"
"作成し、その中に 537MB のテキストファイルを作成しています:"

#. Tag: screen
#: tuning_cgroups.xml:303
#, no-c-format
msgid ""
"&prompt.plain-root;mkdir /io-cgroup\n"
"&prompt.plain-root;cd /io-cgroup\n"
"&prompt.plain-root;yes this is a test file | head -c 537MB &gt; file1.txt\n"
"&prompt.plain-root;yes this is a test file | head -c 537MB &gt; file2.txt\n"
msgstr ""
"&prompt.plain-root;mkdir /io-cgroup\n"
"&prompt.plain-root;cd /io-cgroup\n"
"&prompt.plain-root;yes this is a test file | head -c 537MB &gt; file1.txt\n"
"&prompt.plain-root;yes this is a test file | head -c 537MB &gt; file2.txt\n"

#. Tag: para
#: tuning_cgroups.xml:308
#, no-c-format
msgid ""
"To run the examples open three command shells. Two shells are for reader "
"processes, and one shell is for running the steps that control I/O. In the "
"examples, each command prompt is labeled to indicate if it represents one of "
"the reader processes, or I/O."
msgstr ""
"例を実行するために 3 つのコマンドシェルを開いてください。 2 つのシェルは読み"
"込み側のプロセスを動作させるもので、残りの 1 つは I/O を制御するためのもので"
"す。下記の例では行頭に reader1/reader2 (読み込み側), io-controller (制御側) "
"としてラベルを示しています。"

#. Tag: title
#: tuning_cgroups.xml:316
#, no-c-format
msgid "Using cgroup-v1"
msgstr "cgroup-v1 での例"

#. Tag: para
#: tuning_cgroups.xml:317
#, no-c-format
msgid ""
"The following proportional weight policy files can be used to grant a reader "
"process a higher priority for I/O operations than other reader processes "
"accessing the same disk."
msgstr ""
"下記の比例型重み付けポリシーファイルは読み込み側のプロセスに対して作用するも"
"ので、他のプロセスよりも優先的にアクセスができるようにするためのものです。"

#. Tag: para
#: tuning_cgroups.xml:324
#, no-c-format
msgid ""
"<filename>blkio.bfq.weight</filename> (available in kernels starting with "
"version 5.0 with blk-mq and when using the BFQ I/O scheduler)"
msgstr ""
"<filename>blkio.bfq.weight</filename> (カーネルバージョン 5.0 もしくはそれ以"
"降の blk-mq を使用していて、かつ BFQ I/O スケジューラを使用する場合にのみ利用"
"できるファイルです)"

#. Tag: para
#: tuning_cgroups.xml:330
#, no-c-format
msgid ""
"To test this, run a single reader process (in the examples, reading from an "
"SSD) without controlling its I/O, using <filename>file2.txt</filename> :"
msgstr ""
"まずはシェルのうちの 1 つを利用して、 I/O 制御を行わない場合の "
"<filename>file2.txt</filename> の読み込み性能を調べてみます:"

#. Tag: screen
#: tuning_cgroups.xml:335
#, no-c-format
msgid ""
" \n"
"&prompt.io-controller;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.io-controller;echo $$; dd if=file2.txt of=/dev/null bs=4k "
"count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 1.33049 s, 404 MB/s\n"
msgstr ""
" \n"
"&prompt.io-controller;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.io-controller;echo $$; dd if=file2.txt of=/dev/null bs=4k "
"count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 1.33049 s, 404 MB/s\n"

#. Tag: para
#: tuning_cgroups.xml:343
#, no-c-format
msgid "Now run a background process reading from the same disk:"
msgstr "次に、同じディスクに対して読み込み処理を同時に 2 つ動作させます:"

#. Tag: screen
#: tuning_cgroups.xml:346
#, no-c-format
msgid ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5220\n"
"...\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 2.61592 s, 205 MB/s\n"
msgstr ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5220\n"
"...\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 2.61592 s, 205 MB/s\n"

#. Tag: para
#: tuning_cgroups.xml:357
#, no-c-format
msgid ""
"Each process gets half of the throughput for I/O operations. Next, set up "
"two control groups&mdash;one for each process&mdash;verify that BFQ is used, "
"and set a different weight for reader2:"
msgstr ""
"上記のとおり、 I/O 性能はおおよそ半分になっていることがわかります。次に、それ"
"ぞれの読み込み側プロセスに適用できるよう、 2 種類の制御グループを作成します。"
"このとき、 BFQ が適用されていることを確認しておいてください。また、 reader2 "
"に対して異なる重み付けを行います:"

#. Tag: screen
#: tuning_cgroups.xml:363
#, no-c-format
msgid ""
"\n"
"&prompt.io-controller;cd /sys/fs/cgroup/blkio/\n"
"&prompt.blkio;mkdir reader1\n"
"&prompt.blkio;mkdir reader2\n"
"&prompt.blkio;echo 5220 &gt; reader1/cgroup.procs\n"
"&prompt.blkio;echo 5251 &gt; reader2/cgroup.procs\n"
"&prompt.blkio;cat /sys/block/sda/queue/scheduler\n"
"mq-deadline kyber [bfq] none\n"
"&prompt.blkio;cat reader1/blkio.bfq.weight\n"
"100\n"
"&prompt.blkio;echo 200 &gt; reader2/blkio.bfq.weight\n"
"&prompt.blkio;cat reader2/blkio.bfq.weight\n"
"200\n"
msgstr ""
"\n"
"&prompt.io-controller;cd /sys/fs/cgroup/blkio/\n"
"&prompt.blkio;mkdir reader1\n"
"&prompt.blkio;mkdir reader2\n"
"&prompt.blkio;echo 5220 &gt; reader1/cgroup.procs\n"
"&prompt.blkio;echo 5251 &gt; reader2/cgroup.procs\n"
"&prompt.blkio;cat /sys/block/sda/queue/scheduler\n"
"mq-deadline kyber [bfq] none\n"
"&prompt.blkio;cat reader1/blkio.bfq.weight\n"
"100\n"
"&prompt.blkio;echo 200 &gt; reader2/blkio.bfq.weight\n"
"&prompt.blkio;cat reader2/blkio.bfq.weight\n"
"200\n"

#. Tag: para
#: tuning_cgroups.xml:377
#, no-c-format
msgid ""
"With these settings and reader1 in the background, reader2 should have "
"higher throughput than previously:"
msgstr ""
"上記の設定で reader1 と reader2 を動作させると、 reader2 に対して優先的に性能"
"が割り当てられるようになります:"

#. Tag: screen
#: tuning_cgroups.xml:381
#, no-c-format
msgid ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5220\n"
"...\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 2.06604 s, 260 MB/s\n"
msgstr ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5220\n"
"...\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 2.06604 s, 260 MB/s\n"

#. Tag: para
#: tuning_cgroups.xml:392
#, no-c-format
msgid ""
"The higher proportional weight resulted in higher throughput for reader2. "
"Now double its weight again:"
msgstr ""
"reader2 に対する重み付けの値を大きくすればするほど、より優先的に性能が割り当"
"てられるようになります。さらに値を倍にしてみます:"

#. Tag: screen
#: tuning_cgroups.xml:396
#, no-c-format
msgid ""
"\n"
"&prompt.blkio;cat reader1/blkio.bfq.weight\n"
"100\n"
"&prompt.blkio;echo 400 &gt; reader2/blkio.bfq.weight\n"
"&prompt.blkio;cat reader2/blkio.bfq.weight\n"
"400\n"
msgstr ""
"\n"
"&prompt.blkio;cat reader1/blkio.bfq.weight\n"
"100\n"
"&prompt.blkio;echo 400 &gt; reader2/blkio.bfq.weight\n"
"&prompt.blkio;cat reader2/blkio.bfq.weight\n"
"400\n"

#. Tag: para
#: tuning_cgroups.xml:403
#, no-c-format
msgid "This results in another increase in throughput for reader2:"
msgstr "これにより、 reader2 側がさらに高い性能を得るようになります:"

#. Tag: screen
#: tuning_cgroups.xml:406
#, no-c-format
msgid ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5220\n"
"...\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 1.69026 s, 318 MB/s\n"
msgstr ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5220\n"
"...\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 1.69026 s, 318 MB/s\n"

#. Tag: title
#: tuning_cgroups.xml:419
#, no-c-format
msgid "Using cgroup-v2"
msgstr "cgroup-v2 での例"

#. Tag: para
#: tuning_cgroups.xml:420
#, no-c-format
msgid "First set up your test environment as shown at the beginning of this chapter."
msgstr "まずは前の章の手順に従ってテスト環境を準備してください。"

#. Tag: para
#: tuning_cgroups.xml:424
#, no-c-format
msgid ""
"Then make sure that the Block IO controller is not active, as that is for "
"cgroup-v1. To do this, boot with kernel parameter "
"<option>cgroup_no_v1=blkio</option> . Verify that this parameter was used, "
"and that the IO controller (cgroup-v2) is available:"
msgstr ""
"次にブロック IO コントローラ (cgroup-v1) の動作を停止します。これを行うには、"
"カーネルのパラメータに <option>cgroup_no_v1=blkio</option> を追加します。この"
"パラメータが使用されていることを確認したあと、 IO コントローラ (cgroup-v2) が"
"利用できるかどうかを確認します:"

#. Tag: screen
#: tuning_cgroups.xml:430
#, no-c-format
msgid ""
"\n"
"&prompt.io-controller;cat /proc/cmdline\n"
"BOOT_IMAGE=... cgroup_no_v1=blkio ...\n"
"&prompt.io-controller;cat /sys/fs/cgroup/unified/cgroup.controllers\n"
"io\n"
msgstr ""
"\n"
"&prompt.io-controller;cat /proc/cmdline\n"
"BOOT_IMAGE=... cgroup_no_v1=blkio ...\n"
"&prompt.io-controller;cat /sys/fs/cgroup/unified/cgroup.controllers\n"
"io\n"

#. Tag: para
#: tuning_cgroups.xml:436
#, no-c-format
msgid "Next, enable the IO controller:"
msgstr "あとは IO コントローラを有効化します:"

#. Tag: screen
#: tuning_cgroups.xml:439
#, no-c-format
msgid ""
"\n"
"&prompt.io-controller;cd /sys/fs/cgroup/unified/\n"
"&prompt.unified;echo '+io' &gt; cgroup.subtree_control\n"
"&prompt.unified;cat cgroup.subtree_control\n"
"io\n"
msgstr ""
"\n"
"&prompt.io-controller;cd /sys/fs/cgroup/unified/\n"
"&prompt.unified;echo '+io' &gt; cgroup.subtree_control\n"
"&prompt.unified;cat cgroup.subtree_control\n"
"io\n"

#. Tag: para
#: tuning_cgroups.xml:445
#, no-c-format
msgid ""
"Now run all the test steps, similarly to the steps for cgroup-v1. Note that "
"some of the directories are different. Run a single reader process (in the "
"examples, reading from an SSD) without controlling its I/O, using file2.txt:"
msgstr ""
"あとは cgroup-v1 と同じような手順を実行するだけです。ただし、ディレクトリのう"
"ちのいくつかが異なることに注意してください。まずはシェルのうちの 1 つを利用し"
"て、 I/O 制御を行わない場合の <filename>file2.txt</filename> の読み込み性能を"
"調べてみます (この例では、 SSD から読み込みを行っています):"

#. Tag: screen
#: tuning_cgroups.xml:451
#, no-c-format
msgid ""
"\n"
"&prompt.unified;cd -\n"
"&prompt.io-controller;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.io-controller;echo $$; dd if=file2.txt of=/dev/null bs=4k "
"count=131072\n"
"5633\n"
"[...]\n"
msgstr ""
"\n"
"&prompt.unified;cd -\n"
"&prompt.io-controller;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.io-controller;echo $$; dd if=file2.txt of=/dev/null bs=4k "
"count=131072\n"
"5633\n"
"[...]\n"

#. Tag: para
#: tuning_cgroups.xml:458
#, no-c-format
msgid ""
"Run a background process reading from the same disk and note your throughput "
"values:"
msgstr ""
"次に、同じディスクに対して読み込み処理を同時に 2 つ動作させて性能を確認しま"
"す:"

#. Tag: screen
#: tuning_cgroups.xml:462
#, no-c-format
msgid ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5633\n"
"[...]\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5703\n"
"[...]\n"
msgstr ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5633\n"
"[...]\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5703\n"
"[...]\n"

#. Tag: para
#: tuning_cgroups.xml:471
#, no-c-format
msgid ""
"Each process gets half of the throughput for I/O operations. Set up two "
"control groups&mdash;one for each process&mdash;verify that BFQ is the "
"active scheduler, and set a different weight for reader2:"
msgstr ""
"上記のとおり、 I/O 性能はおおよそ半分になっていることがわかります。次に、それ"
"ぞれの読み込み側プロセスに適用できるよう、 2 種類の制御グループを作成して、そ"
"れぞれのプロセスに割り当てます。このとき、 BFQ が適用されていることを確認して"
"おいてください。また、 reader2 に対して異なる重み付けを行います:"

#. Tag: screen
#: tuning_cgroups.xml:475
#, no-c-format
msgid ""
"\n"
"&prompt.io-controller;cd -\n"
"&prompt.unified;mkdir reader1\n"
"&prompt.unified;mkdir reader2\n"
"&prompt.unified;echo 5633 &gt; reader1/cgroup.procs\n"
"&prompt.unified;echo 5703 &gt; reader2/cgroup.procs\n"
"&prompt.unified;cat /sys/block/sda/queue/scheduler\n"
"mq-deadline kyber [bfq] none\n"
"&prompt.unified;cat reader1/io.bfq.weight\n"
"default 100\n"
"&prompt.unified;echo 200 &gt; reader2/io.bfq.weight\n"
"&prompt.unified;cat reader2/io.bfq.weight\n"
"default 200\n"
msgstr ""
"\n"
"&prompt.io-controller;cd -\n"
"&prompt.unified;mkdir reader1\n"
"&prompt.unified;mkdir reader2\n"
"&prompt.unified;echo 5633 &gt; reader1/cgroup.procs\n"
"&prompt.unified;echo 5703 &gt; reader2/cgroup.procs\n"
"&prompt.unified;cat /sys/block/sda/queue/scheduler\n"
"mq-deadline kyber [bfq] none\n"
"&prompt.unified;cat reader1/io.bfq.weight\n"
"default 100\n"
"&prompt.unified;echo 200 &gt; reader2/io.bfq.weight\n"
"&prompt.unified;cat reader2/io.bfq.weight\n"
"default 200\n"

#. Tag: para
#: tuning_cgroups.xml:489
#, no-c-format
msgid ""
"Test your throughput with the new settings. reader2 should show an increase "
"in throughput."
msgstr ""
"上記の設定で reader1 と reader2 を動作させると、 reader2 に対して優先的に性能"
"が割り当てられるようになります:"

#. Tag: screen
#: tuning_cgroups.xml:493
#, no-c-format
msgid ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1 of=/dev/null bs=4k\n"
"5633\n"
"[...]\n"
"&prompt.reader2;echo $$; dd if=file2 of=/dev/null bs=4k count=131072\n"
"5703\n"
"[...]\n"
msgstr ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1 of=/dev/null bs=4k\n"
"5633\n"
"[...]\n"
"&prompt.reader2;echo $$; dd if=file2 of=/dev/null bs=4k count=131072\n"
"5703\n"
"[...]\n"

#. Tag: para
#: tuning_cgroups.xml:502
#, no-c-format
msgid "Try doubling the weight again for reader2, and testing the new setting:"
msgstr ""
"reader2 に対する重み付けの値を大きくすればするほど、より優先的に性能が割り当"
"てられるようになります。さらに値を倍にしてみます:"

#. Tag: screen
#: tuning_cgroups.xml:505
#, no-c-format
msgid ""
"\n"
"&prompt.reader2;echo 400 &gt; reader1/blkio.bfq.weight\n"
"&prompt.reader2;cat reader2/blkio.bfq.weight\n"
"400\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"[...]\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"[...]\n"
msgstr ""
"\n"
"&prompt.reader2;echo 400 &gt; reader1/blkio.bfq.weight\n"
"&prompt.reader2;cat reader2/blkio.bfq.weight\n"
"400\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"[...]\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"[...]\n"

#. Tag: title
#: tuning_cgroups.xml:519
#, no-c-format
msgid "More information"
msgstr "さらなる情報"

#. Tag: para
#: tuning_cgroups.xml:523
#, no-c-format
msgid ""
"Kernel documentation (package <systemitem>kernel-source</systemitem> ): "
"files in <filename>/usr/src/linux/Documentation/admin-guide/cgroup-v1</"
"filename> and file <filename>/usr/src/linux/Documentation/admin-guide/cgroup-"
"v2.rst</filename> ."
msgstr ""
"カーネルのドキュメンテーション (<systemitem>kernel-source</systemitem> パッ"
"ケージ内):  <filename>/usr/src/linux/Documentation/admin-guide/cgroup-v1</"
"filename> および <filename>/usr/src/linux/Documentation/admin-guide/cgroup-"
"v2.rst</filename> の各ファイル"

#. Tag: para
#: tuning_cgroups.xml:530
#, no-c-format
msgid ""
"<link xlink:href=\"https://lwn.net/Articles/604609/\"/> &mdash;Brown, Neil: "
"Control Groups Series (2014, 7 parts)."
msgstr ""
"<link xlink:href=\"https://lwn.net/Articles/604609/\"/>: Brown, Neil: "
"Control Groups Series (2014 年, 7 部構成)"

#. Tag: para
#: tuning_cgroups.xml:536
#, no-c-format
msgid ""
"<link xlink:href=\"https://lwn.net/Articles/243795/\"/> &mdash;Corbet, "
"Jonathan: Controlling memory use in containers (2007)."
msgstr ""
"<link xlink:href=\"https://lwn.net/Articles/243795/\"/>: Corbet, Jonathan: "
"Controlling memory use in containers (2007 年)"

#. Tag: para
#: tuning_cgroups.xml:542
#, no-c-format
msgid ""
"<link xlink:href=\"https://lwn.net/Articles/236038/\"/> &mdash;Corbet, "
"Jonathan: Process containers (2007)."
msgstr ""
"<link xlink:href=\"https://lwn.net/Articles/236038/\"/>: Corbet, Jonathan: "
"Process containers (2007 年)"

