# translation of tuning_cgroups.xml.po to Japanese
# Japanese translations for PACKAGE package
# PACKAGE パッケージに対する英訳.
#
# Automatically generated, 2018.
# Yasuhiko Kamata <belphegor@belbel.or.jp>, 2019, 2020.
msgid ""
msgstr ""
"Project-Id-Version: tuning_cgroups.xml\n"
"Report-Msgid-Bugs-To: https://github.com/belphegor-belbel/doc-opensuse-ja\n"
"POT-Creation-Date: 2020-08-25 22:16+0000\n"
"PO-Revision-Date: 2020-08-06 10:59+0900\n"
"Last-Translator: Yasuhiko Kamata <belphegor@belbel.or.jp>\n"
"Language-Team: Japanese <opensuse-ja@opensuse.org>\n"
"Language: ja\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: KBabel 1.11.4\n"

#. Tag: title
#: tuning_cgroups.xml:22
#, no-c-format
msgid "Kernel Control Groups"
msgstr "カーネルコントロールグループ"

#. Tag: para
#: tuning_cgroups.xml:25
#, no-c-format
msgid ""
"Kernel Control Groups ( <quote>cgroups</quote> ) are a kernel feature that "
"allows assigning and limiting hardware and system resources for processes. "
"Processes can also be organized in a hierarchical tree structure."
msgstr ""
"カーネルコントロールグループ ( <quote>cgroups</quote> ) は、プロセスに対して"
"ハードウエアやシステムの資源を割り当てたり、制限したりするための仕組みです。"
"この機能を利用することで、プロセスをツリー構造で管理することができるようにな"
"ります。"

#. Tag: title
#: tuning_cgroups.xml:38
#, no-c-format
msgid "Overview"
msgstr "概要"

#. Tag: para
#: tuning_cgroups.xml:39
#, no-c-format
msgid ""
"Every process is assigned exactly one administrative cgroup. cgroups are "
"ordered in a hierarchical tree structure. You can set resource limitations, "
"such as CPU, memory, disk I/O, or network bandwidth usage, for single "
"processes or for whole branches of the hierarchy tree."
msgstr ""
"それぞれのプロセスは正確に 1 つの管理用 cgroup に割り当てられます。 cgroup は"
"階層構造型のツリー (木構造) として管理するもので、その構造の任意の箇所 (枝) "
"もしくは 1 つのプロセスに対して、 CPU やメモリ、ディスクの I/O やネットワーク"
"帯域などのリソース制限を割り当てます。"

#. Tag: para
#: tuning_cgroups.xml:45
#, no-c-format
msgid ""
"On &productname;, &systemd; uses cgroups to organize all processes in "
"groups, which &systemd; calls slices. &systemd; also provides an interface "
"for setting cgroup properties."
msgstr ""
"&productname; では、 &systemd; が cgroup を利用してグループ内の全てのプロセス"
"を管理しています。この場合、 &systemd; はグループをスライスと呼んでいます。 "
"&systemd; には、 cgroup の設定を行なうためのインターフェイスも用意されていま"
"す。"

#. Tag: para
#: tuning_cgroups.xml:50
#, no-c-format
msgid ""
"The command <command>systemd-cgls</command> displays the hierarchy tree."
msgstr ""
"<command>systemd-cgls</command> コマンドでは、階層構造を表示することができま"
"す。"

#. Tag: para
#: tuning_cgroups.xml:54
#, no-c-format
msgid ""
"This chapter is an overview. For more details, refer to the listed "
"references."
msgstr ""
"本章は概要のみを説明しています。詳しい説明については、列挙されている参照先を"
"お読みください。"

#. Tag: title
#: tuning_cgroups.xml:61
#, no-c-format
msgid "Setting Resource Limits"
msgstr "リソース制限の設定"

#. Tag: title
#: tuning_cgroups.xml:63
#, no-c-format
msgid "Implicit Resource Consumption"
msgstr "暗黙のリソース消費について"

#. Tag: para
#: tuning_cgroups.xml:64
#, no-c-format
msgid ""
"Be aware that resource consumption implicitly depends on the environment "
"where your workload executes (for example, size of data structures in "
"libraries/kernel, forking behavior of utilities, computational efficiency). "
"Hence it is recommended to (re)calibrate your limits should the environment "
"change."
msgstr ""
"暗黙のうちに消費され、実行環境によって異なるリソースが存在することに注意して"
"ください。これにはたとえば、ライブラリやカーネル内のデータ構造のほか、利用し"
"ているユーティリティの fork() 処理の振る舞い、計算の効率性などがあります。こ"
"のようなことから、実行環境を変えた場合は、リソース制限を再計算する必要があり"
"ます。"

#. Tag: para
#: tuning_cgroups.xml:71
#, no-c-format
msgid ""
"Limitations to <literal>cgroups</literal> can be set with the "
"<command>systemctl set-property</command> command. The syntax is:"
msgstr ""
"<literal>cgroup</literal> に対する制限は、 <command>systemctl set-property</"
"command> コマンドで設定します。書式は下記のとおりです:"

#. Tag: screen
#: tuning_cgroups.xml:75
#, no-c-format
msgid ""
"&prompt.root;<command>systemctl set-property [--runtime] <replaceable>NAME</"
"replaceable> <replaceable>PROPERTY1</replaceable>=<replaceable>VALUE</"
"replaceable> [<replaceable>PROPERTY2</replaceable>=<replaceable>VALUE</"
"replaceable>]</command>"
msgstr ""
"&prompt.root;<command>systemctl set-property [--runtime] <replaceable>名前</"
"replaceable> <replaceable>プロパティ_1</replaceable>=<replaceable>値</"
"replaceable> [<replaceable>プロパティ_2</replaceable>=<replaceable>値</"
"replaceable>]</command>"

#. Tag: para
#: tuning_cgroups.xml:76
#, no-c-format
msgid ""
"Optionally, use the <option>--runtime</option> option. With this option, set "
"limits do not persist after the next reboot."
msgstr ""
"必要であれば <option>--runtime</option> オプションを指定することもできます。"
"このオプションを指定すると、再起動後には指定した制限が適用されなくなります。"

#. Tag: para
#: tuning_cgroups.xml:80
#, no-c-format
msgid ""
"Replace <replaceable>NAME</replaceable> with a &systemd; service slice, "
"scope, socket, mount, or swap name. Replace properties with one or more of "
"the following:"
msgstr ""
"なお、 <replaceable>名前</replaceable> には &systemd; のスライス名やスコープ"
"名、ソケット名やマウント名、スワップ名を指定します。また、プロパティには下記"
"のものがあります:"

#. Tag: term
#: tuning_cgroups.xml:87
#, no-c-format
msgid "<literal>CPUAccounting=</literal> <option>[yes|no]</option>"
msgstr "<literal>CPUAccounting=</literal> <option>[yes|no]</option>"

#. Tag: para
#: tuning_cgroups.xml:89
#, no-c-format
msgid ""
"Turns on CPU usage accounting. This property takes <literal>yes</literal> "
"and <literal>no</literal> as arguments."
msgstr ""
"CPU 使用率の算出を行なうかどうかを指定します。値には <literal>yes</literal> "
"(はい) または <literal>no</literal> (いいえ) のいずれかを指定することができま"
"す。"

#. Tag: screen
#: tuning_cgroups.xml:96
#, no-c-format
msgid ""
"&prompt.root;<command>systemctl set-property user.slice CPUAccounting=yes</"
"command>"
msgstr ""
"&prompt.root;<command>systemctl set-property user.slice CPUAccounting=yes</"
"command>"

#. Tag: term
#: tuning_cgroups.xml:100
#, no-c-format
msgid "<literal>CPUQuota=</literal> <replaceable>PERCENTAGE</replaceable>"
msgstr "<literal>CPUQuota=</literal> <replaceable>パーセント値</replaceable>"

#. Tag: para
#: tuning_cgroups.xml:102
#, no-c-format
msgid ""
"Assigns a CPU time to processes. The value is a percentage followed by a "
"<literal>%</literal> as suffix. This implies <literal>CPUAccounting=yes</"
"literal> ."
msgstr ""
"プロセスに対して CPU 時間の割り当てを行ないます。この値はパーセント単位で指定"
"するため、末尾に <literal>%</literal> を付けて指定します。この設定を行なう"
"と、 <literal>CPUAccounting=yes</literal> が設定されたものとして扱われます。"

#. Tag: screen
#: tuning_cgroups.xml:110
#, no-c-format
msgid ""
"&prompt.root;<command>systemctl set-property user.slice CPUQuota=50%</"
"command>"
msgstr ""
"&prompt.root;<command>systemctl set-property user.slice CPUQuota=50%</"
"command>"

#. Tag: term
#: tuning_cgroups.xml:114
#, no-c-format
msgid "<literal>MemoryAccounting=</literal> <option>[yes|no]</option>"
msgstr "<literal>MemoryAccounting=</literal> <option>[yes|no]</option>"

#. Tag: para
#: tuning_cgroups.xml:116
#, no-c-format
msgid ""
"Turns on memory usage accounting. This property takes <literal>yes</literal> "
"and <literal>no</literal> as arguments."
msgstr ""
"メモリ使用率の算出を行なうかどうかを指定します。値には <literal>yes</"
"literal> (はい) または <literal>no</literal> (いいえ) のいずれかを指定するこ"
"とができます。"

#. Tag: screen
#: tuning_cgroups.xml:123
#, no-c-format
msgid ""
"&prompt.root;<command>systemctl set-property user.slice "
"MemoryAccounting=yes</command>"
msgstr ""
"&prompt.root;<command>systemctl set-property user.slice "
"MemoryAccounting=yes</command>"

#. Tag: term
#: tuning_cgroups.xml:127
#, no-c-format
msgid "<literal>MemoryLow=</literal> <replaceable>BYTES</replaceable>"
msgstr "<literal>MemoryLow=</literal> <replaceable>容量</replaceable>"

#. Tag: para
#: tuning_cgroups.xml:129
#, no-c-format
msgid ""
"Unused memory from processes below this limit will not be reclaimed for "
"other use. Use suffixes K, M, G or T for <replaceable>BYTES</replaceable> . "
"This implies <literal>MemoryAccounting=yes</literal> ."
msgstr ""
"プロセスからの未使用メモリが指定した容量より少ない場合、メモリを他の用途に再"
"利用しないようにします。 <replaceable>容量</replaceable> の値には K (キロ), "
"M (メガ), G (ギガ), T (テラ) の各接頭辞を使用することができます。この設定を行"
"なうと、 <literal>MemoryAccounting=yes</literal> が設定されたものとして扱われ"
"ます。"

#. Tag: screen
#: tuning_cgroups.xml:138
#, no-c-format
msgid ""
"&prompt.root;<command>systemctl set-property nginx.service MemoryLow=512M</"
"command>"
msgstr ""
"&prompt.root;<command>systemctl set-property nginx.service MemoryLow=512M</"
"command>"

#. Tag: para
#: tuning_cgroups.xml:141
#, no-c-format
msgid ""
"This setting is available only if the unified control group hierarchy is "
"used, and disables <option>MemoryLimit=</option> . To enable the unified "
"control group hierarchy, append <option>systemd.unified_cgroup_hierarchy=1</"
"option> as a kernel command line parameter to the &grub; boot loader. Refer "
"to <xref linkend=\"cha-grub2\"/> for more details about configuring &grub;."
msgstr ""
"この設定は、統合型のコントロールグループ階層構造を使用している場合にのみ利用"
"することができます。また、 <option>MemoryLimit=</option> の設定が無効化されま"
"す。統合型のコントロールグループ階層構造を使用するには、 &grub; ブートローダ"
"のカーネルコマンドラインパラメータに対して、 <option>systemd."
"unified_cgroup_hierarchy=1</option> を追加してください。なお、 &grub; の設定"
"に関する詳細は、 <xref linkend=\"cha-grub2\"/> をお読みください。"

#. Tag: term
#: tuning_cgroups.xml:153
#, no-c-format
msgid "<literal>MemoryHigh=</literal> <replaceable>BYTES</replaceable>"
msgstr "<literal>MemoryHigh=</literal> <replaceable>容量</replaceable>"

#. Tag: para
#: tuning_cgroups.xml:155
#, no-c-format
msgid ""
"If more memory above this limit is used, memory is aggressively taken away "
"from the processes. Use suffixes K, M, G or T for <replaceable>BYTES</"
"replaceable> . This implies <literal>MemoryAccounting=yes</literal> . For "
"example:"
msgstr ""
"この制限以上にメモリを使用した場合、プロセスからできる限り積極的にメモリを取"
"り除こうとする動きをします。 <replaceable>容量</replaceable> の値には K (キ"
"ロ), M (メガ), G (ギガ), T (テラ) の各接頭辞を使用することができます。この設"
"定を行なうと、 <literal>MemoryAccounting=yes</literal> が設定されたものとして"
"扱われます。たとえば下記のようになります:"

#. Tag: screen
#: tuning_cgroups.xml:162
#, no-c-format
msgid ""
"&prompt.root;<command>systemctl set-property nginx.service MemoryHigh=2G</"
"command>"
msgstr ""
"&prompt.root;<command>systemctl set-property nginx.service MemoryHigh=2G</"
"command>"

#. Tag: title
#: tuning_cgroups.xml:164
#, no-c-format
msgid "Unified Control Group Hierarchy"
msgstr "統合型のコントロールグループ階層構造について"

#. Tag: para
#: tuning_cgroups.xml:165
#, no-c-format
msgid ""
"This setting is available only if the unified control group hierarchy is "
"used, and disables <option>MemoryLimit=</option> . To enable the unified "
"control group hierarchy, append <option>systemd.unified_cgroup_hierarchy=1</"
"option> as a kernel command line parameter to the &grub; boot loader. For "
"more details about configuring &grub;, see <xref linkend=\"cha-grub2\"/> ."
msgstr ""
"この設定は、統合型のコントロールグループ階層構造を使用している場合にのみ利用"
"することができます。また、 <option>MemoryLimit=</option> の設定が無効化されま"
"す。統合型のコントロールグループ階層構造を使用するには、 &grub; ブートローダ"
"のカーネルコマンドラインパラメータに対して、 <option>systemd."
"unified_cgroup_hierarchy=1</option> を追加してください。なお、 &grub; の設定"
"に関する詳細は、 <xref linkend=\"cha-grub2\"/> をお読みください。"

#. Tag: term
#: tuning_cgroups.xml:177
#, no-c-format
msgid "<literal>MemoryMax=</literal> <replaceable>BYTES</replaceable>"
msgstr "<literal>MemoryMax=</literal> <replaceable>容量</replaceable>"

#. Tag: para
#: tuning_cgroups.xml:179
#, no-c-format
msgid ""
"Sets a maximum limit for used memory. Processes will be killed if they use "
"more memory than allowed. Use suffixes K, M, G or T for <replaceable>BYTES</"
"replaceable> . This implies <literal>MemoryAccounting=yes</literal> ."
msgstr ""
"メモリの最大値を設定することができます。プロセスがこの値を超えてメモリを確保"
"した場合、プロセスは kill されます。 <replaceable>容量</replaceable> の値に"
"は K (キロ), M (メガ), G (ギガ), T (テラ) の各接頭辞を使用することができま"
"す。この設定を行なうと、 <literal>MemoryAccounting=yes</literal> が設定された"
"ものとして扱われます。"

#. Tag: screen
#: tuning_cgroups.xml:188
#, no-c-format
msgid ""
"&prompt.root;<command>systemctl set-property nginx.service MemoryMax=4G</"
"command>"
msgstr ""
"&prompt.root;<command>systemctl set-property nginx.service MemoryMax=4G</"
"command>"

#. Tag: term
#: tuning_cgroups.xml:192
#, no-c-format
msgid "<literal>DeviceAllow=</literal>"
msgstr "<literal>DeviceAllow=</literal>"

#. Tag: para
#: tuning_cgroups.xml:194
#, no-c-format
msgid ""
"Allows read ( <literal>r</literal> ), write ( <literal>w</literal> ) and "
"mknod ( <literal>m</literal> ) access. The command takes a device node "
"specifier and a list of <literal>r</literal> , <literal>w</literal> or "
"<literal>m</literal> , separated by a white space."
msgstr ""
"読み込み ( <literal>r</literal> ), 書き込み ( <literal>w</literal> ), mknod "
"( <literal>m</literal> ) のアクセスを許可します。このコマンドの場合、デバイス"
"ノードの指定と、スペースを入れて <literal>r</literal> , <literal>w</"
"literal>, <literal>m</literal> の一覧を指定する必要があります。"

#. Tag: para
#: tuning_cgroups.xml:200
#, no-c-format
msgid "Example:"
msgstr "例:"

#. Tag: screen
#: tuning_cgroups.xml:203
#, no-c-format
msgid ""
"&prompt.root;<command>systemctl set-property system.slice DeviceAllow=\"/dev/"
"sdb1 r\"</command>"
msgstr ""
"&prompt.root;<command>systemctl set-property system.slice DeviceAllow=\"/dev/"
"sdb1 r\"</command>"

#. Tag: term
#: tuning_cgroups.xml:207
#, no-c-format
msgid "<literal>DevicePolicy=</literal> <option>[auto|closed|strict]</option>"
msgstr "<literal>DevicePolicy=</literal> <option>[auto|closed|strict]</option>"

#. Tag: para
#: tuning_cgroups.xml:209
#, no-c-format
msgid ""
"When set to <literal>strict</literal> , only access to devices that are "
"listed in <literal>DeviceAllow</literal> is allowed. <literal>closed</"
"literal> additionally allows access to standard pseudo devices including "
"<filename>/dev/null</filename> , <filename>/dev/zero</filename> , <filename>/"
"dev/full</filename> , <filename>/dev/random</filename> , and <filename>/dev/"
"urandom</filename> . <literal>auto</literal> allows access to all devices if "
"no specific rule is defined in <literal>DeviceAllow</literal> . "
"<literal>auto</literal> is the default setting."
msgstr ""
"<literal>strict</literal> に設定した場合、 <literal>DeviceAllow</literal> に"
"列挙したデバイスにのみアクセスを許可するようになります。 <literal>closed</"
"literal> を指定すると、 <filename>/dev/null</filename> , <filename>/dev/"
"zero</filename> , <filename>/dev/full</filename> , <filename>/dev/random</"
"filename> , <filename>/dev/urandom</filename> などの標準疑似デバイスにもアク"
"セスを許可するようになります。 <literal>auto</literal> を設定した場合は、 "
"<literal>DeviceAllow</literal> でルールが設定されない場合、全てのデバイスへの"
"アクセスが許可されるようになります。既定値は <literal>auto</literal> です。"

#. Tag: para
#: tuning_cgroups.xml:224
#, no-c-format
msgid ""
"For more details and a complete list of properties, see <command>man systemd."
"resource-control</command> ."
msgstr ""
"プロパティに対する詳細と完全な一覧については、 <command>man systemd.resource-"
"control</command> で表示されるマニュアルページをお読みください。"

#. Tag: title
#: tuning_cgroups.xml:231
#, no-c-format
msgid "Preventing Fork Bombs with TasksMax"
msgstr "TasksMax を利用した fork ボムの防止"

#. Tag: para
#: tuning_cgroups.xml:232
#, no-c-format
msgid ""
"&systemd; 228 shipped with a <literal>DefaultTasksMax</literal> limit of "
"512. This limited the number of processes any system unit can create at one "
"time to 512. Previous versions had no default limit. The goal was to improve "
"security by preventing runaway processes from creating excessive forks, or "
"spawning enough threads to exhaust system resources."
msgstr ""
"&systemd; 228 では <literal>DefaultTasksMax</literal> の制限が 512 に設定され"
"ています。これは systemd の各ユニットに対して、作成できるプロセス数の制限を行"
"なうための仕組みで、それ以前のバージョンでは制限がありませんでした。このよう"
"に設定を行なったのは、 fork によって作成される過剰なプロセスやスレッドによっ"
"てシステム資源が枯渇してしまうのを防ぐ、セキュリティ改善のためのものです。"

#. Tag: para
#: tuning_cgroups.xml:240
#, no-c-format
msgid ""
"However, it soon became apparent that there is not a single default that "
"applies to all use cases. 512 is not low enough to prevent a runaway process "
"from crashing a system, especially when other resources such as CPU and RAM "
"are not restricted, and not high enough for processes that create a lot of "
"threads, such as databases. In &systemd; 234, the default was changed to "
"15%, which is 4915 tasks (15% of the kernel limit of 32768; see "
"<command>cat /proc/sys/kernel/pid_max</command> ). This default is compiled, "
"and can be changed in configuration files. The compiled defaults are "
"documented in <filename>/etc/systemd/system.conf</filename> . You can edit "
"this file to override the defaults, though there are other methods we will "
"show in the following sections."
msgstr ""
"しかしながら、この既定値は全ての用途に対して適用可能なものではありません。ま"
"た、 CPU やメモリの使用量に対する直接的な制限ではありませんので、 512 に設定"
"してもシステムの安定性を保つことができるかどうかはわかりませんし、データベー"
"スシステムなどのように 512 個以上のプロセスを動作させなければならない場合もあ"
"ります。 &systemd; 234 では、この値が 15% (カーネル側に設定されたプロセス数の"
"最大値である 32768 の 15% 。詳しくは <command>cat /proc/sys/kernel/pid_max</"
"command> をご覧ください) に設定されていますが、必要に応じて設定ファイルで変更"
"することができます。具体的には、 <filename>/etc/systemd/system.conf</"
"filename> ファイルを編集して設定を行なってください。なお、下記ではそれ以外の"
"方法について説明しています。"

#. Tag: title
#: tuning_cgroups.xml:257
#, no-c-format
msgid "Finding the Current Default TasksMax Values"
msgstr "現時点での既定の TasksMax 値の検出"

#. Tag: para
#: tuning_cgroups.xml:258
#, no-c-format
msgid ""
"&productname; ships with two custom configurations that override the "
"upstream defaults for system units and for user slices, and sets them both "
"to <literal>infinity</literal> . <filename>/usr/lib/systemd/system.conf.d/20-"
"suse-defaults.conf</filename> contains these lines:"
msgstr ""
"&productname; では、 systemd のユニットやユーザスライスに対する提供元の既定値"
"を上書きするため、独自の設定ファイルが 2 つ用意され、いずれも "
"<literal>infinity</literal> に設定されています。 <filename>/usr/lib/systemd/"
"system.conf.d/20-suse-defaults.conf</filename> には、下記のような設定が書かれ"
"ています:"

#. Tag: screen
#: tuning_cgroups.xml:265
#, no-c-format
msgid ""
"\n"
"[Manager]\n"
"DefaultTasksMax=infinity\n"
msgstr ""
"\n"
"[Manager]\n"
"DefaultTasksMax=infinity\n"

#. Tag: para
#: tuning_cgroups.xml:269
#, no-c-format
msgid ""
"<filename>/usr/lib/systemd/system/user-.slice.d/20-suse-defaults.conf</"
"filename> contains these lines:"
msgstr ""
"もう 1 つの存在である <filename>/usr/lib/systemd/system/user-.slice.d/20-"
"suse-defaults.conf</filename> には、下記のような設定が書かれています:"

#. Tag: screen
#: tuning_cgroups.xml:273
#, no-c-format
msgid ""
"[Slice]\n"
"TasksMax=infinity\n"
msgstr ""
"[Slice]\n"
"TasksMax=infinity\n"

#. Tag: para
#: tuning_cgroups.xml:276
#, no-c-format
msgid ""
"<literal>infinity</literal> means having no limit. It is not a requirement "
"to change the default, but setting some limits may help to prevent system "
"crashes from runaway processes."
msgstr ""
"<literal>infinity</literal> は無制限の意味です。特に要件がなければ既定値を変"
"更する必要はありませんが、必要であれば設定を変更してください。"

#. Tag: title
#: tuning_cgroups.xml:284
#, no-c-format
msgid "Overriding the DefaultTasksMax Value"
msgstr "DefaultTasksMax 値の設定"

#. Tag: para
#: tuning_cgroups.xml:285
#, no-c-format
msgid ""
"Change the global <literal>DefaultTasksMax</literal> value by creating a new "
"override file, <filename>/etc/systemd/system.conf.d/10-system-tasksmax.conf</"
"filename> , and write the following lines to set a new default limit of 256 "
"tasks per system unit:"
msgstr ""
"グローバルな <literal>DefaultTasksMax</literal> の値を変更したい場合は、設定"
"を上書きするための新しい設定ファイル <filename>/etc/systemd/system.conf.d/10-"
"system-tasksmax.conf</filename> を作成して対応してください。この設定ファイル"
"には、下記のような内容を記述します (下記の例では、 systemd のユニットごとに最"
"大 256 個までのタスク制限を設定します):"

#. Tag: screen
#: tuning_cgroups.xml:292
#, no-c-format
msgid ""
"\n"
"[Manager]\n"
"DefaultTasksMax=256\n"
msgstr ""
"\n"
"[Manager]\n"
"DefaultTasksMax=256\n"

#. Tag: para
#: tuning_cgroups.xml:296
#, no-c-format
msgid "Load the new setting, then verify that it changed:"
msgstr "新しい設定を読み込んで、設定が反映されたことを確認します:"

#. Tag: screen
#: tuning_cgroups.xml:299
#, no-c-format
msgid ""
"&prompt.sudo;systemctl daemon-reload\n"
"&prompt.user;systemctl show --property DefaultTasksMax\n"
"DefaultTasksMax=256\n"
msgstr ""
"&prompt.sudo;systemctl daemon-reload\n"
"&prompt.user;systemctl show --property DefaultTasksMax\n"
"DefaultTasksMax=256\n"

#. Tag: para
#: tuning_cgroups.xml:303
#, no-c-format
msgid ""
"Adjust this default value to suit your needs. You can set higher limits on "
"individual services as needed. This example is for MariaDB. First check the "
"current active value:"
msgstr ""
"設定値はお使いのシステムの要件に合わせて指定してください。また、特定のサービ"
"スに限定して制限を高くすることもできます。たとえば MariaDB で設定を変更したい"
"場合、まずは現在の設定値を確認します:"

#. Tag: screen
#: tuning_cgroups.xml:308
#, no-c-format
msgid ""
"\n"
"&prompt.user;systemctl status mariadb.service\n"
"  ● mariadb.service - MariaDB database server\n"
"   Loaded: loaded (/usr/lib/systemd/system/mariadb.service; disabled; vendor "
"preset&gt;\n"
"   Active: active (running) since Tue 2020-05-26 14:15:03 PDT; 27min ago\n"
"     Docs: man:mysqld(8)\n"
"           https://mariadb.com/kb/en/library/systemd/\n"
" Main PID: 11845 (mysqld)\n"
"   Status: \"Taking your SQL requests now...\"\n"
"    Tasks: 30 (limit: 256)\n"
"   CGroup: /system.slice/mariadb.service\n"
"           └─11845 /usr/sbin/mysqld --defaults-file=/etc/my.cnf --"
"user=mysql\n"
msgstr ""
"\n"
"&prompt.user;systemctl status mariadb.service\n"
"  ● mariadb.service - MariaDB database server\n"
"   Loaded: loaded (/usr/lib/systemd/system/mariadb.service; disabled; vendor "
"preset&gt;\n"
"   Active: active (running) since Tue 2020-05-26 14:15:03 PDT; 27min ago\n"
"     Docs: man:mysqld(8)\n"
"           https://mariadb.com/kb/en/library/systemd/\n"
" Main PID: 11845 (mysqld)\n"
"   Status: \"Taking your SQL requests now...\"\n"
"    Tasks: 30 (limit: 256)\n"
"   CGroup: /system.slice/mariadb.service\n"
"           └─11845 /usr/sbin/mysqld --defaults-file=/etc/my.cnf --"
"user=mysql\n"

#. Tag: para
#: tuning_cgroups.xml:321
#, no-c-format
msgid ""
"The Tasks line shows that MariaDB currently has 30 tasks running, and has an "
"upper limit of the default 256, which is inadequate for a database. The "
"following example demonstrates how to raise MariaDB's limit to 8192. Create "
"a new override file with <command>systemctl edit</command> , and enter the "
"new value:"
msgstr ""
"<quote>Tasks</quote> 以下には現在動作中のタスク数 (30 個) と上限 (256 個) が"
"示されています。負荷の高いデータベースシステムとしては不十分な値であることか"
"ら、たとえば MariaDB のみを 8192 個までに拡大してみることにします。設定値を変"
"更するには、 <command>systemctl edit</command> コマンドを実行して、下記のよう"
"な設定を記入します:"

#. Tag: screen
#: tuning_cgroups.xml:328
#, no-c-format
msgid ""
"&prompt.sudo;systemctl edit mariadb.service\n"
"\n"
"[Service]\n"
"TasksMax=8192\n"
"\n"
"&prompt.user;systemctl status mariadb.service \n"
"● mariadb.service - MariaDB database server\n"
"   Loaded: loaded (/usr/lib/systemd/system/mariadb.service; disabled; vendor "
"preset: disab&gt;\n"
"  Drop-In: /etc/systemd/system/mariadb.service.d\n"
"           └─override.conf\n"
"   Active: active (running) since Tue 2020-06-02 17:57:48 PDT; 7min ago\n"
"     Docs: man:mysqld(8)\n"
"           https://mariadb.com/kb/en/library/systemd/\n"
"  Process: 3446 ExecStartPre=/usr/lib/mysql/mysql-systemd-helper upgrade "
"(code=exited, sta&gt;\n"
"  Process: 3440 ExecStartPre=/usr/lib/mysql/mysql-systemd-helper install "
"(code=exited, sta&gt;\n"
" Main PID: 3452 (mysqld)\n"
"   Status: \"Taking your SQL requests now...\"\n"
"    Tasks: 30 (limit: 8192)\n"
"   CGroup: /system.slice/mariadb.service\n"
"           └─3452 /usr/sbin/mysqld --defaults-file=/etc/my.cnf --user=mysql\n"
msgstr ""
"&prompt.sudo;systemctl edit mariadb.service\n"
"\n"
"[Service]\n"
"TasksMax=8192\n"
"\n"
"&prompt.user;systemctl status mariadb.service \n"
"● mariadb.service - MariaDB database server\n"
"   Loaded: loaded (/usr/lib/systemd/system/mariadb.service; disabled; vendor "
"preset: disab&gt;\n"
"  Drop-In: /etc/systemd/system/mariadb.service.d\n"
"           └─override.conf\n"
"   Active: active (running) since Tue 2020-06-02 17:57:48 PDT; 7min ago\n"
"     Docs: man:mysqld(8)\n"
"           https://mariadb.com/kb/en/library/systemd/\n"
"  Process: 3446 ExecStartPre=/usr/lib/mysql/mysql-systemd-helper upgrade "
"(code=exited, sta&gt;\n"
"  Process: 3440 ExecStartPre=/usr/lib/mysql/mysql-systemd-helper install "
"(code=exited, sta&gt;\n"
" Main PID: 3452 (mysqld)\n"
"   Status: \"Taking your SQL requests now...\"\n"
"    Tasks: 30 (limit: 8192)\n"
"   CGroup: /system.slice/mariadb.service\n"
"           └─3452 /usr/sbin/mysqld --defaults-file=/etc/my.cnf --user=mysql\n"

#. Tag: para
#: tuning_cgroups.xml:349
#, no-c-format
msgid ""
"<command>systemctl edit</command> creates an override file, <filename>/etc/"
"systemd/system/mariadb.service.d/override.conf</filename> , that contains "
"only the changes you want to apply to the existing unit file. The value does "
"not have to be 8192, but should be whatever limit is appropriate for your "
"workloads."
msgstr ""
"<command>systemctl edit</command> コマンドは <filename>/etc/systemd/system/"
"mariadb.service.d/override.conf</filename> という名前の上書き用設定ファイルを"
"作成します。ここには既存のユニットファイルに対する上書き値のみが保存されま"
"す。もちろん 8192 でなくてもかまいません。お使いの要件に合わせて設定してくだ"
"さい。"

#. Tag: title
#: tuning_cgroups.xml:359
#, no-c-format
msgid "Default TasksMax Limit on Users"
msgstr "ユーザに対する既定の TasksMax 制限"

#. Tag: para
#: tuning_cgroups.xml:360
#, no-c-format
msgid ""
"The default limit on users should be fairly high, because user sessions need "
"more resources. Set your own default for users by creating a new file, for "
"example <filename>/etc/systemd/system/user-.slice.d/user-taskmask.conf</"
"filename> . The following example sets a default of 16284:"
msgstr ""
"ユーザに対する既定の制限値は十分に高く設定されています。これは、ユーザセッ"
"ションではより多くのリソースを必要とするためです。独自の制限を設定したい場合"
"は、 <filename>/etc/systemd/system/user-.slice.d/user-taskmask.conf</"
"filename> のような設定ファイルを作成し、その中に設定値を記述してください。下"
"記の例では、タスクの最大値を 16284 に設定しています:"

#. Tag: screen
#: tuning_cgroups.xml:367
#, no-c-format
msgid ""
"\n"
"[Slice]\n"
"TasksMax=16284\n"
msgstr ""
"\n"
"[Slice]\n"
"TasksMax=16284\n"

#. Tag: para
#: tuning_cgroups.xml:371
#, no-c-format
msgid "Then reload systemd to load the new value, and verify the change:"
msgstr ""
"あとは systemd に対して設定値の再読み込みを指示し、設定が変更されたことを確認"
"します:"

#. Tag: screen
#: tuning_cgroups.xml:374
#, no-c-format
msgid ""
"&prompt.sudo;systemctl daemon-reload\n"
"\n"
"&prompt.user;systemctl show --property TasksMax user-.slice\n"
"TasksMax=16284\n"
"\n"
"&prompt.user;systemctl show --property TasksMax user-1000.slice\n"
"TasksMax=16284\n"
msgstr ""
"&prompt.sudo;systemctl daemon-reload\n"
"\n"
"&prompt.user;systemctl show --property TasksMax user-.slice\n"
"TasksMax=16284\n"
"\n"
"&prompt.user;systemctl show --property TasksMax user-1000.slice\n"
"TasksMax=16284\n"

#. Tag: para
#: tuning_cgroups.xml:382
#, no-c-format
msgid ""
"How do you know what values to use? This varies according to your workloads, "
"system resources, and other resource configurations. When your TasksMax "
"value is too low, you will see error messages such as <emphasis>Failed to "
"fork (Resources temporarily unavailable)</emphasis> , <emphasis>Can't create "
"thread to handle new connection</emphasis> , and <emphasis>Error: Function "
"call 'fork' failed with error code 11, 'Resource temporarily unavailable'</"
"emphasis> ."
msgstr ""
"具体的にどのような設定値にすべきかについては、システムの用途と搭載されている"
"リソースのほか、他のリソース設定によっても異なります。 TasksMax の値が低すぎ"
"る場合は、<emphasis>Failed to fork (Resources temporarily unavailable)</"
"emphasis> (fork に失敗した (リソースが一時的に利用できなくなっている)) や "
"<emphasis>Can't create thread to handle new connection</emphasis> (新しい接続"
"を処理するためのスレッドが作成できない), <emphasis>Error: Function call "
"'fork' failed with error code 11, 'Resource temporarily unavailable'</"
"emphasis> (エラーコード 11 (リソースが一時的に利用できなくなっている) で "
"fork の関数呼び出しが失敗した) などのエラーが発生します。"

#. Tag: para
#: tuning_cgroups.xml:391
#, no-c-format
msgid ""
"For more information on configuring system resources in systemd, see "
"<literal>systemd.resource-control (5)</literal> ."
msgstr ""
"systemd でのシステムリソースの制限の設定方法について、詳しくは"
"<literal>systemd.resource-control (5)</literal> をお読みください。"

#. Tag: title
#: tuning_cgroups.xml:399
#, no-c-format
msgid "Controlling I/O with Proportional Weight Policy"
msgstr "比例型の重み付けポリシーによる I/O の制御"

#. Tag: para
#: tuning_cgroups.xml:400
#, no-c-format
msgid ""
"This section introduces using the Linux kernel's block I/O controller to "
"prioritize I/O operations. The cgroup blkio subsystem controls and monitors "
"access to I/O on block devices. State objects that contain the subsystem "
"parameters for a cgroup are represented as pseudofiles within the cgroup "
"virtual file system, also called a pseudo-filesystem."
msgstr ""
"本章では、 Linux カーネル内に存在する I/O コントローラを利用して、 I/O 処理の"
"優先付けを行なうための方法について説明しています。 cgroup blkio サブシステム"
"では、ブロックデバイスに対する I/O 処理を制御したり監視したりすることができる"
"ほか、 cgroup の仮想ファイルシステム (擬似ファイルシステムとも呼ばれます) 内"
"のファイルとして、 cgroup 向けのサブシステムパラメータを含むステートオブジェ"
"クトが提供されています。"

#. Tag: para
#: tuning_cgroups.xml:407
#, no-c-format
msgid ""
"The examples in this section show how writing values to some of these pseudo-"
"files limits access or bandwidth, and reading values from some of these "
"pseudo-files provides information on I/O operations. Examples are provided "
"for both cgroup-v1 and cgroup-v2."
msgstr ""
"本章では、アクセスや帯域を制限するための擬似ファイルへの書き込み方法のほか、 "
"I/O 処理の関する様々な情報を提供する擬似ファイルの読み込み方法を説明していま"
"す。また、 cgroup-v1 と cgroup-v2 の両方に対する例を示しています。"

#. Tag: para
#: tuning_cgroups.xml:413
#, no-c-format
msgid ""
"You need a test directory containing two files for testing performance and "
"changed settings. A quick way to create test files fully-populated with text "
"is using the <command>yes</command> command. The following example commands "
"create a test directory, and then populate it with two 537 MB text files:"
msgstr ""
"まずはテスト用のディレクトリを作成し、その中にファイルを 2 つ作成して性能のテ"
"ストを行ないます。ある程度のサイズのファイルを作成するため、本章では "
"<command>yes</command> コマンドを使用します。下記の例ではテストディレクトリを"
"作成し、その中に 537MB のテキストファイルを作成しています:"

#. Tag: screen
#: tuning_cgroups.xml:420
#, no-c-format
msgid ""
"&prompt.plain-root;mkdir /io-cgroup\n"
"&prompt.plain-root;cd /io-cgroup\n"
"&prompt.plain-root;yes this is a test file | head -c 537MB &gt; file1.txt\n"
"&prompt.plain-root;yes this is a test file | head -c 537MB &gt; file2.txt\n"
msgstr ""
"&prompt.plain-root;mkdir /io-cgroup\n"
"&prompt.plain-root;cd /io-cgroup\n"
"&prompt.plain-root;yes this is a test file | head -c 537MB &gt; file1.txt\n"
"&prompt.plain-root;yes this is a test file | head -c 537MB &gt; file2.txt\n"

#. Tag: para
#: tuning_cgroups.xml:425
#, no-c-format
msgid ""
"To run the examples open three command shells. Two shells are for reader "
"processes, and one shell is for running the steps that control I/O. In the "
"examples, each command prompt is labeled to indicate if it represents one of "
"the reader processes, or I/O."
msgstr ""
"例を実行するために 3 つのコマンドシェルを開いてください。 2 つのシェルは読み"
"込み側のプロセスを動作させるもので、残りの 1 つは I/O を制御するためのもので"
"す。下記の例では行頭に reader1/reader2 (読み込み側), io-controller (制御側) "
"としてラベルを示しています。"

#. Tag: title
#: tuning_cgroups.xml:433
#, no-c-format
msgid "Using cgroup-v1"
msgstr "cgroup-v1 での例"

#. Tag: para
#: tuning_cgroups.xml:434
#, no-c-format
msgid ""
"The following proportional weight policy files can be used to grant a reader "
"process a higher priority for I/O operations than other reader processes "
"accessing the same disk."
msgstr ""
"下記の比例型重み付けポリシーファイルは読み込み側のプロセスに対して作用するも"
"ので、他のプロセスよりも優先的にアクセスができるようにするためのものです。"

#. Tag: para
#: tuning_cgroups.xml:441
#, no-c-format
msgid ""
"<filename>blkio.weight</filename> (only available in kernels up to version "
"4.20 with legacy block layer and when using the CFQ I/O scheduler)"
msgstr ""
"<filename>blkio.weight</filename> (カーネルバージョン 4.20 もしくはそれ以前の"
"古いブロックレイヤを使用していて、かつ CFQ I/O スケジューラを使用する場合にの"
"み利用できるファイルです)"

#. Tag: para
#: tuning_cgroups.xml:447
#, no-c-format
msgid ""
"<filename>blkio.bfq.weight</filename> (available in kernels starting with "
"version 5.0 with blk-mq and when using BFQ I/O scheduler)"
msgstr ""
"<filename>blkio.bfq.weight</filename> (カーネルバージョン 5.0 もしくはそれ以"
"降の blk-mq を使用していて、かつ BFQ I/O スケジューラを使用する場合にのみ利用"
"できるファイルです)"

#. Tag: para
#: tuning_cgroups.xml:453
#, no-c-format
msgid ""
"To test this, run a single reader process (in the examples, reading from a "
"SSD) without controlling its I/O, using <filename>file2.txt</filename> :"
msgstr ""
"まずはシェルのうちの 1 つを利用して、 I/O 制御を行なわない場合の "
"<filename>file2.txt</filename> の読み込み性能を調べてみます:"

#. Tag: screen
#: tuning_cgroups.xml:458
#, no-c-format
msgid ""
" \n"
"&prompt.io-controller;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.io-controller;echo $$; dd if=file2.txt of=/dev/null bs=4k "
"count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 1.33049 s, 404 MB/s\n"
msgstr ""
" \n"
"&prompt.io-controller;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.io-controller;echo $$; dd if=file2.txt of=/dev/null bs=4k "
"count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 1.33049 s, 404 MB/s\n"

#. Tag: para
#: tuning_cgroups.xml:466
#, no-c-format
msgid "Now run a background process reading from the same disk:"
msgstr "次に、同じディスクに対して読み込み処理を同時に 2 つ動作させます:"

#. Tag: screen
#: tuning_cgroups.xml:469
#, no-c-format
msgid ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5220\n"
"...\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 2.61592 s, 205 MB/s\n"
msgstr ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5220\n"
"...\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 2.61592 s, 205 MB/s\n"

#. Tag: para
#: tuning_cgroups.xml:480
#, no-c-format
msgid ""
"Each process gets half of the throughput for I/O operations. Next, set up "
"two control groups&mdash;one for each process&mdash;verify that BFQ is used, "
"and set a different weight for reader2:"
msgstr ""
"上記のとおり、 I/O 性能はおおよそ半分になっていることがわかります。次に、それ"
"ぞれの読み込み側プロセスに適用できるよう、 2 種類の制御グループを作成します。"
"このとき、 BFQ が適用されていることを確認しておいてください。また、 reader2 "
"に対して異なる重み付けを行ないます:"

#. Tag: screen
#: tuning_cgroups.xml:486
#, no-c-format
msgid ""
"\n"
"&prompt.io-controller;cd /sys/fs/cgroup/blkio/\n"
"&prompt.blkio;mkdir reader1\n"
"&prompt.blkio;mkdir reader2\n"
"&prompt.blkio;echo 5220 &gt; reader1/cgroup.procs\n"
"&prompt.blkio;echo 5251 &gt; reader2/cgroup.procs\n"
"&prompt.blkio;cat /sys/block/sda/queue/scheduler\n"
"mq-deadline kyber [bfq] none\n"
"&prompt.blkio;cat reader1/blkio.bfq.weight\n"
"100\n"
"&prompt.blkio;echo 200 &gt; reader2/blkio.bfq.weight\n"
"&prompt.blkio;cat reader2/blkio.bfq.weight\n"
"200\n"
msgstr ""
"\n"
"&prompt.io-controller;cd /sys/fs/cgroup/blkio/\n"
"&prompt.blkio;mkdir reader1\n"
"&prompt.blkio;mkdir reader2\n"
"&prompt.blkio;echo 5220 &gt; reader1/cgroup.procs\n"
"&prompt.blkio;echo 5251 &gt; reader2/cgroup.procs\n"
"&prompt.blkio;cat /sys/block/sda/queue/scheduler\n"
"mq-deadline kyber [bfq] none\n"
"&prompt.blkio;cat reader1/blkio.bfq.weight\n"
"100\n"
"&prompt.blkio;echo 200 &gt; reader2/blkio.bfq.weight\n"
"&prompt.blkio;cat reader2/blkio.bfq.weight\n"
"200\n"

#. Tag: para
#: tuning_cgroups.xml:500
#, no-c-format
msgid ""
"With these settings and reader1 in the background, reader2 should have "
"higher throughput than previously:"
msgstr ""
"上記の設定で reader1 と reader2 を動作させると、 reader2 に対して優先的に性能"
"が割り当てられるようになります:"

#. Tag: screen
#: tuning_cgroups.xml:504
#, no-c-format
msgid ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5220\n"
"...\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 2.06604 s, 260 MB/s\n"
msgstr ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5220\n"
"...\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 2.06604 s, 260 MB/s\n"

#. Tag: para
#: tuning_cgroups.xml:515
#, no-c-format
msgid ""
"The higher proportional weight resulted in higher throughput for reader2. "
"Now double its weight again:"
msgstr ""
"reader2 に対する重み付けの値を大きくすればするほど、より優先的に性能が割り当"
"てられるようになります。さらに値を倍にしてみます:"

#. Tag: screen
#: tuning_cgroups.xml:519
#, no-c-format
msgid ""
"\n"
"&prompt.blkio;cat reader1/blkio.bfq.weight\n"
"100\n"
"&prompt.blkio;echo 400 &gt; reader2/blkio.bfq.weight\n"
"&prompt.blkio;cat reader2/blkio.bfq.weight\n"
"400\n"
msgstr ""
"\n"
"&prompt.blkio;cat reader1/blkio.bfq.weight\n"
"100\n"
"&prompt.blkio;echo 400 &gt; reader2/blkio.bfq.weight\n"
"&prompt.blkio;cat reader2/blkio.bfq.weight\n"
"400\n"

#. Tag: para
#: tuning_cgroups.xml:526
#, no-c-format
msgid "This results in another increase in throughput for reader2:"
msgstr "これにより、 reader2 側がさらに高い性能を得るようになります:"

#. Tag: screen
#: tuning_cgroups.xml:529
#, no-c-format
msgid ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5220\n"
"...\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 1.69026 s, 318 MB/s\n"
msgstr ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5220\n"
"...\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5251\n"
"131072+0 records in\n"
"131072+0 records out\n"
"536870912 bytes (537 MB, 512 MiB) copied, 1.69026 s, 318 MB/s\n"

#. Tag: title
#: tuning_cgroups.xml:542
#, no-c-format
msgid "Using cgroup-v2"
msgstr "cgroup-v2 での例"

#. Tag: para
#: tuning_cgroups.xml:543
#, no-c-format
msgid ""
"First set up your test environment as shown at the beginning of this chapter."
msgstr "まずは前の章の手順に従ってテスト環境を準備してください。"

#. Tag: para
#: tuning_cgroups.xml:547
#, no-c-format
msgid ""
"Then make sure that the Block IO controller is not active, as that is for "
"cgroup-v1. To do this, boot with kernel parameter "
"<option>cgroup_no_v1=blkio</option> . Verify that this parameter was used, "
"and that the IO controller (cgroup-v2) is available:"
msgstr ""
"次にブロック IO コントローラ (cgroup-v1) の動作を停止します。これを行なうに"
"は、カーネルのパラメータに <option>cgroup_no_v1=blkio</option> を追加します。"
"このパラメータが使用されていることを確認したあと、 IO コントローラ (cgroup-"
"v2) が利用できるかどうかを確認します:"

#. Tag: screen
#: tuning_cgroups.xml:553
#, no-c-format
msgid ""
"\n"
"&prompt.io-controller;cat /proc/cmdline\n"
"BOOT_IMAGE=... cgroup_no_v1=blkio ...\n"
"&prompt.io-controller;cat /sys/fs/cgroup/unified/cgroup.controllers\n"
"io\n"
msgstr ""
"\n"
"&prompt.io-controller;cat /proc/cmdline\n"
"BOOT_IMAGE=... cgroup_no_v1=blkio ...\n"
"&prompt.io-controller;cat /sys/fs/cgroup/unified/cgroup.controllers\n"
"io\n"

#. Tag: para
#: tuning_cgroups.xml:559
#, no-c-format
msgid "Next, enable the IO controller:"
msgstr "あとは IO コントローラを有効化します:"

#. Tag: screen
#: tuning_cgroups.xml:562
#, no-c-format
msgid ""
"\n"
"&prompt.io-controller;cd /sys/fs/cgroup/unified/\n"
"&prompt.unified;echo '+io' &gt; cgroup.subtree_control\n"
"&prompt.unified;cat cgroup.subtree_control\n"
"io\n"
msgstr ""
"\n"
"&prompt.io-controller;cd /sys/fs/cgroup/unified/\n"
"&prompt.unified;echo '+io' &gt; cgroup.subtree_control\n"
"&prompt.unified;cat cgroup.subtree_control\n"
"io\n"

#. Tag: para
#: tuning_cgroups.xml:568
#, no-c-format
msgid ""
"Now run all the test steps, similarly to the steps for cgroup-v1. Note that "
"some of the directories are different. Run a single reader process (in the "
"examples, reading from a SSD) without controlling its I/O, using file2.txt:"
msgstr ""
"あとは cgroup-v1 と同じような手順を実行するだけです。ただし、ディレクトリのう"
"ちのいくつかが異なることに注意してください。まずはシェルのうちの 1 つを利用し"
"て、 I/O 制御を行なわない場合の <filename>file2.txt</filename> の読み込み性能"
"を調べてみます (この例では、 SSD から読み込みを行なっています):"

#. Tag: screen
#: tuning_cgroups.xml:574
#, no-c-format
msgid ""
"\n"
"&prompt.unified;cd -\n"
"&prompt.io-controller;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.io-controller;echo $$; dd if=file2.txt of=/dev/null bs=4k "
"count=131072\n"
"5633\n"
"[...]\n"
msgstr ""
"\n"
"&prompt.unified;cd -\n"
"&prompt.io-controller;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.io-controller;echo $$; dd if=file2.txt of=/dev/null bs=4k "
"count=131072\n"
"5633\n"
"[...]\n"

#. Tag: para
#: tuning_cgroups.xml:581
#, no-c-format
msgid ""
"Run a background process reading from the same disk and note your throughput "
"values:"
msgstr ""
"次に、同じディスクに対して読み込み処理を同時に 2 つ動作させて性能を確認しま"
"す:"

#. Tag: screen
#: tuning_cgroups.xml:585
#, no-c-format
msgid ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5633\n"
"[...]\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5703\n"
"[...]\n"
msgstr ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"5633\n"
"[...]\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"5703\n"
"[...]\n"

#. Tag: para
#: tuning_cgroups.xml:594
#, no-c-format
msgid ""
"Each process gets half of the throughput for I/O operations. Set up two "
"control groups, one for each process, verify that BFQ is the active "
"scheduler, and set a different weight for reader2:"
msgstr ""
"上記のとおり、 I/O 性能はおおよそ半分になっていることがわかります。次に、それ"
"ぞれの読み込み側プロセスに適用できるよう、 2 種類の制御グループを作成します。"
"このとき、 BFQ が適用されていることを確認しておいてください。また、 reader2 "
"に対して異なる重み付けを行ないます:"

#. Tag: screen
#: tuning_cgroups.xml:598
#, no-c-format
msgid ""
"\n"
"&prompt.io-controller;cd -\n"
"&prompt.unified;mkdir reader1\n"
"&prompt.unified;mkdir reader2\n"
"&prompt.unified;echo 5633 &gt; reader1/cgroup.procs\n"
"&prompt.unified;echo 5703 &gt; reader2/cgroup.procs\n"
"&prompt.unified;cat /sys/block/sda/queue/scheduler\n"
"mq-deadline kyber [bfq] none\n"
"&prompt.unified;cat reader1/io.bfq.weight\n"
"default 100\n"
"&prompt.unified;echo 200 &gt; reader2/io.bfq.weight\n"
"&prompt.unified;cat reader2/io.bfq.weight\n"
"default 200\n"
msgstr ""
"\n"
"&prompt.io-controller;cd -\n"
"&prompt.unified;mkdir reader1\n"
"&prompt.unified;mkdir reader2\n"
"&prompt.unified;echo 5633 &gt; reader1/cgroup.procs\n"
"&prompt.unified;echo 5703 &gt; reader2/cgroup.procs\n"
"&prompt.unified;cat /sys/block/sda/queue/scheduler\n"
"mq-deadline kyber [bfq] none\n"
"&prompt.unified;cat reader1/io.bfq.weight\n"
"default 100\n"
"&prompt.unified;echo 200 &gt; reader2/io.bfq.weight\n"
"&prompt.unified;cat reader2/io.bfq.weight\n"
"default 200\n"

#. Tag: para
#: tuning_cgroups.xml:612
#, no-c-format
msgid ""
"Test your throughput with the new settings. reader2 should show an increase "
"in throughput."
msgstr ""
"上記の設定で reader1 と reader2 を動作させると、 reader2 に対して優先的に性能"
"が割り当てられるようになります:"

#. Tag: screen
#: tuning_cgroups.xml:616
#, no-c-format
msgid ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1 of=/dev/null bs=4k\n"
"5633\n"
"[...]\n"
"&prompt.reader2;echo $$; dd if=file2 of=/dev/null bs=4k count=131072\n"
"5703\n"
"[...]\n"
msgstr ""
"\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1 of=/dev/null bs=4k\n"
"5633\n"
"[...]\n"
"&prompt.reader2;echo $$; dd if=file2 of=/dev/null bs=4k count=131072\n"
"5703\n"
"[...]\n"

#. Tag: para
#: tuning_cgroups.xml:625
#, no-c-format
msgid "Try doubling the weight again for reader2, and testing the new setting:"
msgstr ""
"reader2 に対する重み付けの値を大きくすればするほど、より優先的に性能が割り当"
"てられるようになります。さらに値を倍にしてみます:"

#. Tag: screen
#: tuning_cgroups.xml:628
#, no-c-format
msgid ""
"\n"
"&prompt.reader2;echo 400 &gt; reader1/blkio.bfq.weight\n"
"&prompt.reader2;cat reader2/blkio.bfq.weight\n"
"400\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"[...]\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"[...]\n"
msgstr ""
"\n"
"&prompt.reader2;echo 400 &gt; reader1/blkio.bfq.weight\n"
"&prompt.reader2;cat reader2/blkio.bfq.weight\n"
"400\n"
"&prompt.reader1;sync; echo 3 &gt; /proc/sys/vm/drop_caches\n"
"&prompt.reader1;echo $$; dd if=file1.txt of=/dev/null bs=4k\n"
"[...]\n"
"&prompt.reader2;echo $$; dd if=file2.txt of=/dev/null bs=4k count=131072\n"
"[...]\n"

#. Tag: title
#: tuning_cgroups.xml:642
#, no-c-format
msgid "For More Information"
msgstr "さらなる情報"

#. Tag: para
#: tuning_cgroups.xml:646
#, fuzzy, no-c-format
msgid ""
"Kernel documentation (package <systemitem>kernel-source</systemitem> ): "
"files in <filename>/usr/src/linux/Documentation/admin-guide/cgroup-v1</"
"filename> and file <filename>/usr/src/linux/Documentation/admin-guide/cgroup-"
"v2.rst</filename> ."
msgstr ""
"カーネルのドキュメンテーション <filename>/usr/src/linux/Documentation/"
"cgroups</filename> (<systemitem>kernel-source</systemitem> パッケージ内)"

#. Tag: para
#: tuning_cgroups.xml:653
#, no-c-format
msgid ""
"<link xlink:href=\"http://lwn.net/Articles/604609/\"/> &mdash;Brown, Neil: "
"Control Groups Series (2014, 7 parts)."
msgstr ""
"<link xlink:href=\"http://lwn.net/Articles/604609/\"/>: Brown, Neil: Control "
"Groups Series (2014 年, 7 部構成)"

#. Tag: para
#: tuning_cgroups.xml:659
#, no-c-format
msgid ""
"<link xlink:href=\"http://lwn.net/Articles/243795/\"/> &mdash;Corbet, "
"Jonathan: Controlling memory use in containers (2007)."
msgstr ""
"<link xlink:href=\"http://lwn.net/Articles/243795/\"/>: Corbet, Jonathan: "
"Controlling memory use in containers (2007 年)"

#. Tag: para
#: tuning_cgroups.xml:665
#, no-c-format
msgid ""
"<link xlink:href=\"http://lwn.net/Articles/236038/\"/> &mdash;Corbet, "
"Jonathan: Process containers (2007)."
msgstr ""
"<link xlink:href=\"http://lwn.net/Articles/236038/\"/>: Corbet, Jonathan: "
"Process containers (2007 年)"
