# translation of tuning_storagescheduler.xml.po to Japanese
# Japanese translations for PACKAGE package
# PACKAGE パッケージに対する英訳.
#
# Automatically generated, 2018.
# Yasuhiko Kamata <belphegor@belbel.or.jp>, 2019.
msgid ""
msgstr ""
"Project-Id-Version: tuning_storagescheduler.xml\n"
"Report-Msgid-Bugs-To: https://github.com/belphegor-belbel/doc-opensuse-ja\n"
"POT-Creation-Date: 2018-07-05 01:25+0000\n"
"PO-Revision-Date: 2019-03-25 16:17+0900\n"
"Last-Translator: Yasuhiko Kamata <belphegor@belbel.or.jp>\n"
"Language-Team: Japanese <opensuse-ja@opensuse.org>\n"
"Language: ja\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: KBabel 1.11.4\n"

#. Tag: title
#: tuning_storagescheduler.xml:9
#, no-c-format
msgid "Tuning I/O Performance"
msgstr "I/O 性能のチューニング"

#. Tag: para
#: tuning_storagescheduler.xml:16
#, no-c-format
msgid ""
"I/O scheduling controls how input/output operations will be submitted to "
"storage. &productname; offers various I/O algorithms&mdash;called "
"<literal>elevators</literal> &mdash;suiting different workloads. Elevators "
"can help to reduce seek operations and can prioritize I/O requests."
msgstr ""
"I/O スケジューリングの制御とは、ストレージに対して送信される入出力操作をどのような"
"順序にするのかを決めるものです。 &productname; では <literal>エレベータ</literal> "
"と呼ばれる様々な I/O アルゴリズムに対応しています。これにより、様々な使用環境に"
"対応することができるようになっています。エレベータはシーク操作を減らすための"
"ものであるほか、 I/O 要求に対する優先順位付けとしても使用されます。"

#. Tag: para
#: tuning_storagescheduler.xml:22
#, no-c-format
msgid ""
"Choosing the best suited I/O elevator not only depends on the workload, but "
"on the hardware, too. Single ATA disk systems, SSDs, RAID arrays, or network "
"storage systems, for example, each require different tuning strategies."
msgstr ""
"最適な I/O エレベータを選択するにあたって、その根拠となるのは負荷だけではなく、"
"ハードウエアの仕様も含みます。たとえば単一の ATA ディスクと SSD, RAID アレイや"
"ネットワークストレージシステムでは、それぞれ異なるチューニング戦略が必要となります。"

#. Tag: title
#: tuning_storagescheduler.xml:29
#, no-c-format
msgid "Switching I/O Scheduling"
msgstr "I/O スケジューリングの切り替え"

#. Tag: para
#: tuning_storagescheduler.xml:31
#, no-c-format
msgid ""
"&productname; picks a default I/O scheduler at boot-time, which can be "
"changed on the fly per block device. This makes it possible to set different "
"algorithms, for example, for the device hosting the system partition and the "
"device hosting a database."
msgstr ""
"&productname; では起動時に既定の I/O スケジューラを選択しますが、 I/O スケジューラは"
"デバイス単位で即時に変更することができます。これにより、システムパーティションを含んで"
"いるデバイスと、データベースを含んでいるデバイスで別々のアルゴリズムを設定したりする"
"ことができるようになっています。"

#. Tag: para
#: tuning_storagescheduler.xml:38
#, no-c-format
msgid ""
"The default I/O scheduler is chosen for each device based on whether the "
"device reports to be rotational disk or not. For non-rotational disks "
"<systemitem class=\"resource\">DEADLINE</systemitem> I/O scheduler is "
"picked. Other devices default to <systemitem class=\"resource\">CFQ</"
"systemitem> (Completely Fair Queuing). To change this default, use the "
"following boot parameter:"
msgstr ""
"既定の I/O スケジューラは、デバイス側からの情報内に回転型のディスクである旨が書かれて"
"いるかどうかによって決まります。回転型のディスクではない場合、 <systemitem "
"class=\"resource\">DEADLINE</systemitem> I/O スケジューラが選択されます。"
"回転型のディスクである場合は、 <systemitem class=\"resource\">CFQ</systemitem> "
"(Completely Fair Queuing; 完全公平型キューイング) が選択されます。この既定値を"
"変更したい場合は、下記の起動パラメータを設定してください:"

#. Tag: screen
#: tuning_storagescheduler.xml:47
#, no-c-format
msgid "elevator=<replaceable>SCHEDULER</replaceable>"
msgstr "elevator=<replaceable>スケジューラ</replaceable>"

#. Tag: para
#: tuning_storagescheduler.xml:49
#, no-c-format
msgid ""
"Replace <replaceable>SCHEDULER</replaceable> with one of the values "
"<option>cfq</option> , <option>noop</option> , or <option>deadline</"
"option> . See <xref linkend=\"cha.tuning.io.schedulers\"/> for details."
msgstr ""
"ここで、 <replaceable>スケジューラ</replaceable> には <option>cfq</option> ,"
" <option>noop</option> , <option>deadline</option> のいずれかを指定します。"
"詳しくは <xref linkend=\"cha.tuning.io.schedulers\"/> をお読みください。"

#. Tag: para
#: tuning_storagescheduler.xml:56
#, no-c-format
msgid ""
"To change the elevator for a specific device in the running system, run the "
"following command:"
msgstr ""
"動作中のシステム内で、特定のデバイスに対するエレベータを変更したい場合は、下記の"
"コマンドを実行します:"

#. Tag: screen
#: tuning_storagescheduler.xml:61
#, no-c-format
msgid ""
"&prompt.sudo;echo <replaceable>SCHEDULER</replaceable> &gt; /sys/block/"
"<replaceable>DEVICE</replaceable>/queue/scheduler"
msgstr ""
"&prompt.sudo;echo <replaceable>スケジューラ</replaceable> &gt; /sys/block/"
"<replaceable>デバイス名</replaceable>/queue/scheduler"

#. Tag: para
#: tuning_storagescheduler.xml:63
#, no-c-format
msgid ""
"Here, <replaceable>SCHEDULER</replaceable> is one of <option>cfq</option> , "
"<option>noop</option> , or <option>deadline</option> . <replaceable>DEVICE</"
"replaceable> is the block device ( <systemitem>sda</systemitem> for "
"example). Note that this change will not persist during reboot. For "
"permanent I/O scheduler change for a particular device either place the "
"command switching the I/O scheduler into init scripts or add appropriate "
"udev rule into <filename>/lib/udev/rules.d/</filename> . See <filename>/lib/"
"udev/rules.d/60-ssd-scheduler.rules</filename> for an example of such tuning."
msgstr ""
"ここで、 <replaceable>スケジューラ</replaceable> には <option>cfq</option> ,"
" <option>noop</option> , <option>deadline</option> のいずれかを指定します。"
"また <replaceable>デバイス名</replaceable> には、ブロックデバイスのデバイス名"
" (例: <systemitem>sda</systemitem>) を指定します。ただし、この手順で変更を行なった"
"場合、システムを再起動すると既定値に戻ってしまうことに注意してください。特定の"
"デバイスに対して I/O スケジューラを恒久的に変更したい場合は、起動時に実行される"
"スクリプトの中で上記を実行するように設定するか、もしくは <filename>/lib/udev/"
"rules.d/</filename> 内に適切な udev ルールを記述してください。この方法による"
"チューニングについて、詳しくは <filename>/lib/udev/rules.d/60-ssd-scheduler.rules"
"</filename> をお読みください。"

#. Tag: title
#: tuning_storagescheduler.xml:77
#, no-c-format
msgid "Default Scheduler on &zseries;"
msgstr "&zseries; での既定のスケジューラについて"

#. Tag: para
#: tuning_storagescheduler.xml:78
#, no-c-format
msgid ""
"On &zseries;, the default I/O scheduler for a storage device is set by the "
"device driver."
msgstr "&zseries; 環境では、既定の I/O スケジューラはデバイスドライバ側で設定されます。"

#. Tag: title
#: tuning_storagescheduler.xml:85
#, no-c-format
msgid "Available I/O Elevators"
msgstr "利用可能な I/O エレベータ"

#. Tag: para
#: tuning_storagescheduler.xml:87
#, no-c-format
msgid ""
"In the following elevators available on &productname; are listed. Each "
"elevator has a set of tunable parameters, which can be set with the "
"following command:"
msgstr ""
"下記の表には、 &productname; で利用可能なエレベータの一覧を示しています。"
"それぞれのエレベータにはさらに細かくチューニングを行なうための <quote>チューナブル"
"</quote> パラメータが存在していますが、これらは下記のようなコマンドを実行する"
"ことで、設定することができます:"

#. Tag: screen
#: tuning_storagescheduler.xml:93
#, no-c-format
msgid ""
"&prompt.sudo;echo <replaceable>VALUE</replaceable> &gt; /sys/block/"
"<replaceable>DEVICE</replaceable>/queue/iosched/<replaceable>TUNABLE</"
"replaceable>"
msgstr ""
"&prompt.sudo;echo <replaceable>値</replaceable> &gt; /sys/block/"
"<replaceable>デバイス名</replaceable>/queue/iosched/<replaceable>チューナブル名"
"</replaceable>"

#. Tag: para
#: tuning_storagescheduler.xml:95
#, no-c-format
msgid ""
"where <replaceable>VALUE</replaceable> is the desired value for the "
"<replaceable>TUNABLE</replaceable> and <replaceable>DEVICE</replaceable> the "
"block device."
msgstr ""
"ここで、 <replaceable>チューナブル名</replaceable> には下記に示すチューナブルの"
"名前を、 <replaceable>デバイス名</replaceable> にはブロックデバイス名をそれぞれ"
"指定します。"

#. Tag: para
#: tuning_storagescheduler.xml:101
#, no-c-format
msgid ""
"To find out which elevator is the current default, run the following "
"command. The currently selected scheduler is listed in brackets:"
msgstr ""
"また、既定で使用されるエレベータを確認したい場合は、下記のようなコマンドを入力して"
"実行します。現在選択されているエレベータが [] で括られて出力されます:"

#. Tag: screen
#: tuning_storagescheduler.xml:106
#, no-c-format
msgid ""
"&wsI;:~ # cat /sys/block/sda/queue/scheduler\n"
"noop deadline [cfq]"
msgstr ""
"&wsI;:~ # cat /sys/block/sda/queue/scheduler\n"
"noop deadline [cfq]"

#. Tag: para
#: tuning_storagescheduler.xml:109
#, no-c-format
msgid ""
"This file can also contain the string <literal>none</literal> meaning that I/"
"O scheduling does not happen for this device. This is usually because the "
"device uses multi-queue queuing mechanism (refer to <xref linkend=\"cha."
"tuning.io.scsimq\"/> )."
msgstr ""
"このファイルには <literal>none</literal> という文字列が含まれることがありますが、"
"これはそのデバイスに対して、 I/O スケジューリングを行なわない意味になります。これは"
"通常、対象のデバイスがマルチキュー型のキューイング機構を持っている場合に現われる"
"ものです (詳しくは <xref linkend=\"cha.tuning.io.scsimq\"/> をお読みください) 。"

#. Tag: title
#: tuning_storagescheduler.xml:117
#, no-c-format
msgid "<systemitem class=\"resource\">CFQ</systemitem> (Completely Fair Queuing)"
msgstr "<systemitem class=\"resource\">CFQ</systemitem> (Completely Fair Queuing; 完全公平型キューイング)"

#. Tag: para
#: tuning_storagescheduler.xml:118
#, no-c-format
msgid ""
"<systemitem class=\"resource\">CFQ</systemitem> is a fairness-oriented "
"scheduler and is used by default on &productname;. The algorithm assigns "
"each thread a time slice in which it is allowed to submit I/O to disk. This "
"way each thread gets a fair share of I/O throughput. It also allows "
"assigning tasks I/O priorities which are taken into account during "
"scheduling decisions (see <xref linkend=\"cha.tuning.resources.disk.ionice\"/"
"> ). The <systemitem class=\"resource\">CFQ</systemitem> scheduler has the "
"following tunable parameters:"
msgstr ""
"<systemitem class=\"resource\">CFQ</systemitem> は公平性を重視したスケジューラで、"
" &productname; では既定で使用されるスケジューラでもあります。このアルゴリズムでは、"
" I/O をディスクに送信することのできる各スレッドに対して、同じだけのタイムスライスを"
"割り当てます。この仕組みにより、各スレッドに公平な I/O スループットを割り当てる"
"ことになります。なおスケジューリングの決定においては、 I/O 優先順位も考慮して"
"割り当てが行なわれることになります (詳しくは <xref linkend=\"cha.tuning.resources."
"disk.ionice\"/> をお読みください) 。また、 <systemitem class=\"resource\">CFQ"
"</systemitem> スケジューラには下記のチューナブルパラメータが用意されています:"

#. Tag: term
#: tuning_storagescheduler.xml:131
#, no-c-format
msgid ""
"<filename> /sys/block/<replaceable>DEVICE</replaceable>/queue/iosched/"
"slice_idle_us </filename>"
msgstr ""
"<filename> /sys/block/<replaceable>デバイス名</replaceable>/queue/iosched/"
"slice_idle_us </filename>"

#. Tag: para
#: tuning_storagescheduler.xml:136
#, no-c-format
msgid ""
"When a task has no more I/O to submit in its time slice, the I/O scheduler "
"waits for a while before scheduling the next thread. The "
"<filename>slice_idle_us</filename> is the time in microseconds the I/O "
"scheduler waits. File <filename>slice_idle</filename> controls the same "
"tunable but in millisecond units. Waiting for more I/O from a thread can "
"improve locality of I/O. Additionally, it avoids starving processes doing "
"dependent I/O. A process does dependent I/O if it needs a result of one I/O "
"to submit another I/O. For example, if you first need to read an index block "
"to find out a data block to read, these two reads form a dependent I/O."
msgstr ""
"タスクに対して割り当てられたタイムスライス内で、それ以上送信すべき I/O がなくなった"
"場合、 I/O スケジューラはしばらく待機してから次のスレッドに移行します。 <filename>"
"slice_idle_us</filename> では、そのような I/O スケジューラの待機時間を、マイクロ秒"
"単位で指定することができます。 <filename>slice_idle</filename> でも同じ設定を行なう"
"ことができますが、こちらはミリ秒単位での指定になります。 I/O を待機する時間を長く"
"することで、 I/O のローカリティ (局所性) を改善することになります。これに加えて、"
"依存関係にある複数の I/O を行なっているプロセスに対して、タイムスライスを多く割り"
"当てる結果になることから、この処理も改善することができます。依存関係にある I/O とは、"
"一方の I/O が他方の I/O を生み出すような結果になる場合を指します。たとえば、読み込む"
"べきデータブロックを知るためにインデックス (索引) ブロックを読み出すような処理が"
"あった場合、それらは依存関係にある I/O であると言えます。"

#. Tag: para
#: tuning_storagescheduler.xml:150
#, no-c-format
msgid ""
"For media where locality does not play a big role (SSDs, SANs with lots of "
"disks) setting <filename>/sys/block/<replaceable>&lt;device&gt;</"
"replaceable>/queue/iosched/slice_idle_us</filename> to <literal>0</literal> "
"can improve the throughput considerably."
msgstr ""
"なお、ローカリティが性能面で大きな意味を持たない (たとえば SSD や多数のディスクが搭載された"
" SAN など) メディアである場合は、 <filename>/sys/block/<replaceable>デバイス名"
"</replaceable>/queue/iosched/slice_idle_us</filename> を <literal>0</literal> "
"に設定することで、スループットをかなり改善することができます。"

#. Tag: term
#: tuning_storagescheduler.xml:157
#, no-c-format
msgid ""
"<filename> /sys/block/<replaceable>DEVICE</replaceable>/queue/iosched/"
"quantum </filename>"
msgstr ""
"<filename> /sys/block/<replaceable>デバイス名</replaceable>/queue/iosched/"
"quantum </filename>"

#. Tag: para
#: tuning_storagescheduler.xml:162
#, no-c-format
msgid ""
"This option limits the maximum number of requests that are being processed "
"at once by the device. The default value is <literal>4</literal> . For a "
"storage with several disks, this setting can unnecessarily limit parallel "
"processing of requests. Therefore, increasing the value can improve "
"performance. However, it can also cause latency of certain I/O operations to "
"increase because more requests are buffered inside the storage. When "
"changing this value, you can also consider tuning <filename>/sys/block/"
"<replaceable>DEVICE</replaceable>/queue/iosched/slice_async_rq</filename> "
"(the default value is <literal>2</literal> ). This limits the maximum number "
"of asynchronous requests&mdash;usually write requests&mdash;that are "
"submitted in one time slice."
msgstr ""
"このオプションは、デバイス側で一括で処理されるリクエストの最大数を指定します。"
"既定値は <literal>4</literal> です。複数のディスクから構成されるストレージの"
"場合、この設定では不必要なリクエスト同時処理数を設定することになってしまいます。"
"そのため、そのような環境であれば、値を増やすことで性能を改善することができます。"
"ただし、この設定を増やしてしまうことで、ストレージ内にバッファリングされたリクエスト"
"が増えることになってしまいますので、特定の I/O 操作が遅延する結果になることも"
"あります。この値を変更する場合は、 <filename>/sys/block/<replaceable>デバイス名"
"</replaceable>/queue/iosched/slice_async_rq</filename> (既定値: <literal>2</literal> ) "
"についても、変更を検討してください。こちらの値は、一定のタイムスライス内に送信"
"することのできる、非同期リクエスト (通常は書き込みリクエスト) の最大数を指定"
"するためのものです。"

#. Tag: term
#: tuning_storagescheduler.xml:179
#, no-c-format
msgid ""
"<filename>/sys/block/<replaceable>DEVICE</replaceable>/queue/iosched/"
"low_latency</filename>"
msgstr ""
"<filename>/sys/block/<replaceable>デバイス名</replaceable>/queue/iosched/"
"low_latency</filename>"

#. Tag: para
#: tuning_storagescheduler.xml:182
#, no-c-format
msgid ""
"When enabled (which is the default on &productname;) the scheduler may "
"dynamically adjust the length of the time slice by aiming to meet a tuning "
"parameter called the <literal>target_latency</literal> . Time slices are "
"recomputed to meet this <literal>target_latency</literal> and ensure that "
"processes get fair access within a bounded length of time."
msgstr ""
"有効化した場合 (&productname; では既定で有効化されています) 、スケジューラは"
" <literal>target_latency</literal> というチューニングパラメータで指定された"
"値になるよう、動的にタイムスライスを調整するようになります。タイムスライスは、"
"この <literal>target_latency</literal> に適合するように再計算され、限られた"
"時間内でプロセスが公平にアクセスを取得できるようにします。"

#. Tag: term
#: tuning_storagescheduler.xml:193
#, no-c-format
msgid ""
"<filename>/sys/block/<replaceable>DEVICE</replaceable>/queue/iosched/"
"target_latency</filename>"
msgstr ""
"<filename>/sys/block/<replaceable>デバイス名</replaceable>/queue/iosched/"
"target_latency</filename>"

#. Tag: para
#: tuning_storagescheduler.xml:196
#, no-c-format
msgid ""
"Contains an estimated latency time for the <systemitem class=\"resource"
"\">CFQ</systemitem> . <systemitem class=\"resource\">CFQ</systemitem> will "
"use it to calculate the time slice used for every task."
msgstr ""
"<systemitem class=\"resource\">CFQ</systemitem> に対する待機時間の目標値を"
"指定します。 <systemitem class=\"resource\">CFQ</systemitem> では、この値を"
"利用して、各タスクに割り当てるタイムスライスを調整します。"

#. Tag: term
#: tuning_storagescheduler.xml:205
#, no-c-format
msgid ""
"<filename>/sys/block/<replaceable>DEVICE</replaceable>/queue/iosched/"
"group_idle_us</filename>"
msgstr ""
"<filename>/sys/block/<replaceable>デバイス名</replaceable>/queue/iosched/"
"group_idle_us</filename>"

#. Tag: para
#: tuning_storagescheduler.xml:207
#, no-c-format
msgid ""
"To avoid starving of blkio cgroups doing dependent I/O, CFQ waits a bit "
"after completion of I/O for one blkio cgroup before scheduling I/O for a "
"different blkio cgroup. When <literal>slice_idle_us</literal> is set, this "
"parameter does not have a big impact. However, for fast media, the overhead "
"of <literal>slice_idle_us</literal> is generally undesirable. Disabling "
"<literal>slice_idle_us</literal> and setting <literal>group_idle_us</"
"literal> is a method to avoid starvation of blkio cgroups doing dependent I/"
"O with lower overhead. Note that the file <filename>group_idle</filename> "
"controls the same tunable however with millisecond granularity."
msgstr ""
"依存関係にある I/O を行なう際、 blkio cgroup の処理時間が枯渇することを防ぐため、"
" CFQ は異なる blkio cgroup に対する I/O スケジューリングを行なう前に、 I/O が"
"完了しても少しの時間だけ待機する処理を行ないます。 <literal>slice_idle_us</literal> "
"が設定されている場合、このパラメータを設定しても大きな影響は編ません。しかしながら"
"高速なメディアの場合、 <literal>slice_idle_us</literal> によるオーバーヘッドは"
"無視できない大きさになってしまいます。 <literal>slice_idle_us</literal> を無効化"
"して <literal>group_idle_us</literal> を指定することで、依存関係にある I/O を"
"より低いオーバーヘッドで blkio cgroup に処理時間を与えられるようになります。なお、"
" <filename>group_idle</filename> というチューナブルもありますが、こちらはミリ秒"
"の単位で指定します。"

#. Tag: title
#: tuning_storagescheduler.xml:223
#, no-c-format
msgid ""
"Increasing individual thread throughput using <systemitem class=\"resource"
"\">CFQ</systemitem>"
msgstr ""
"<systemitem class=\"resource\">CFQ</systemitem> を利用した個別スレッドに対する"
"スループットの改善"

#. Tag: para
#: tuning_storagescheduler.xml:224
#, no-c-format
msgid ""
"In &productname; &productnumber;, the <literal>low_latency</literal> tuning "
"parameter is enabled by default to ensure that processes get fair access "
"within a bounded length of time. (Note that this parameter was not enabled "
"in versions prior to <phrase os=\"sles;sled\">&sle; 12</phrase> <phrase os="
"\"osuse\">&opensuse; Leap</phrase> .)"
msgstr ""
"&productname; &productnumber; では、 <literal>low_latency</literal> チューニング"
"パラメータが既定で有効化されていて、限られた時間内でプロセスが公平にアクセスを"
"取得できるようになっています (なお、このパラメータは <phrase os=\"sles;sled\">&sle; "
"12</phrase> <phrase os=\"osuse\">&opensuse; Leap</phrase> 以前のバージョンでは"
"有効化されていませんでした) 。"

#. Tag: para
#: tuning_storagescheduler.xml:231
#, no-c-format
msgid ""
"This is usually preferred in a server scenario where processes are executing "
"I/O as part of transactions, as it makes the time needed for each "
"transaction predictable. However, there are scenarios where that is not the "
"desired behavior:"
msgstr ""
"これは通常、プロセスがトランザクションの一部として I/O を実行しているようなサーバ用途"
"で、各トランザクションに必要な時間を予測できるようにするために必要な設定です。しかし"
"ながら、このような動作では問題が発生する場合があります:"

#. Tag: para
#: tuning_storagescheduler.xml:239
#, no-c-format
msgid ""
"If the performance metric of interest is the peak performance of a single "
"process when there is I/O contention."
msgstr "改善したい性能指標が I/O の集中する単一のプロセスである場合。"

#. Tag: para
#: tuning_storagescheduler.xml:245
#, no-c-format
msgid ""
"If a workload must complete as quickly as possible and there are multiple "
"sources of I/O. In this case, unfair treatment from the I/O scheduler may "
"allow the transactions to complete faster: Processes take their full slice "
"and exit quickly, resulting in reduced overall contention."
msgstr ""
"処理をできる限り素早く終わらせなければならず、かつ複数の I/O 発信源が存在するような"
"場合。この場合は、 I/O スケジューラが不公平に扱うことによって、トランザクションを"
"より素早く追わせることができるためです。各プロセスはいったんタイムスライスを入手"
"すると、それをできる限り素早く処理して終わらせようとしますので、これによって全体の"
"競合を防ぐことができるようになります。"

#. Tag: para
#: tuning_storagescheduler.xml:253
#, no-c-format
msgid ""
"To address this, there are two options&mdash;increase "
"<literal>target_latency</literal> or disable <literal>low_latency</"
"literal> . As with all tuning parameters it is important to verify your "
"workload behaves as expected before and after the tuning modification. Take "
"careful note of whether your workload depends on individual process peak "
"performance or scales better with fairness. It should also be noted that the "
"performance will depend on the underlying storage and the correct tuning "
"option for one installation may not be universally true."
msgstr ""
"この問題に対応する手段として、 2 つの方法が用意されています。具体的には、 <literal>"
"target_latency</literal> を増やすか、もしくは <literal>low_latency</literal> "
"を無効にするかです。なお、全てのチューニングパラメータに対して、チューニングによる"
"変更前後で負荷が正しく処理されるかどうかを確認しておく必要があります。また、受け持つ"
"負荷が各プロセスのピーク性能によって決まるのか、それとも公平性によって全体的に"
"改善を行なわなければならないものなのかについても、慎重に確認しておくことを"
"お勧めします。また、性能は下位に存在するストレージに依存して決まるものであり、"
"一方の環境で正しいチューニングであっても、他方の環境では正しくないこともあります。"

#. Tag: para
#: tuning_storagescheduler.xml:264
#, no-c-format
msgid ""
"Find below an example that does not control when I/O starts but is simple "
"enough to demonstrate the point. 32 processes are writing a small amount of "
"data to disk in parallel. Using the &productname; default (enabling "
"<literal>low_latency</literal> ), the result looks as follows:"
msgstr ""
"下記の例は、 I/O の開始時には制御を行なわないものの、シンプルに説明することができる"
"例です。この例では、 32 個のプロセスが小さいサイズの書き込みを並行して行なって"
"います。 &productname; の既定値 (つまり <literal>low_latency</literal> が"
"有効化されている場合) では、結果は下記のようになります:"

#. Tag: screen
#: tuning_storagescheduler.xml:271
#, no-c-format
msgid ""
"&prompt.root;echo 1 &gt; /sys/block/sda/queue/iosched/low_latency\n"
"&prompt.root;time ./dd-test.sh\n"
"10485760 bytes (10 MB) copied, 2.62464 s, 4.0 MB/s\n"
"10485760 bytes (10 MB) copied, 3.29624 s, 3.2 MB/s\n"
"10485760 bytes (10 MB) copied, 3.56341 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.56908 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.53043 s, 3.0 MB/s\n"
"10485760 bytes (10 MB) copied, 3.57511 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.53672 s, 3.0 MB/s\n"
"10485760 bytes (10 MB) copied, 3.5433 s, 3.0 MB/s\n"
"10485760 bytes (10 MB) copied, 3.65474 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.63694 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.90122 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 3.88507 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 3.86135 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 3.84553 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 3.88871 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 3.94943 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 4.12731 s, 2.5 MB/s\n"
"10485760 bytes (10 MB) copied, 4.15106 s, 2.5 MB/s\n"
"10485760 bytes (10 MB) copied, 4.21601 s, 2.5 MB/s\n"
"10485760 bytes (10 MB) copied, 4.35004 s, 2.4 MB/s\n"
"10485760 bytes (10 MB) copied, 4.33387 s, 2.4 MB/s\n"
"10485760 bytes (10 MB) copied, 4.55434 s, 2.3 MB/s\n"
"10485760 bytes (10 MB) copied, 4.52283 s, 2.3 MB/s\n"
"10485760 bytes (10 MB) copied, 4.52682 s, 2.3 MB/s\n"
"10485760 bytes (10 MB) copied, 4.56176 s, 2.3 MB/s\n"
"10485760 bytes (10 MB) copied, 4.62727 s, 2.3 MB/s\n"
"10485760 bytes (10 MB) copied, 4.78958 s, 2.2 MB/s\n"
"10485760 bytes (10 MB) copied, 4.79772 s, 2.2 MB/s\n"
"10485760 bytes (10 MB) copied, 4.78004 s, 2.2 MB/s\n"
"10485760 bytes (10 MB) copied, 4.77994 s, 2.2 MB/s\n"
"10485760 bytes (10 MB) copied, 4.86114 s, 2.2 MB/s\n"
"10485760 bytes (10 MB) copied, 4.88062 s, 2.1 MB/s\n"
"\n"
"real    0m4.978s\n"
"user    0m0.112s\n"
"sys     0m1.544s"
msgstr ""
"&prompt.root;echo 1 &gt; /sys/block/sda/queue/iosched/low_latency\n"
"&prompt.root;time ./dd-test.sh\n"
"10485760 bytes (10 MB) copied, 2.62464 s, 4.0 MB/s\n"
"10485760 bytes (10 MB) copied, 3.29624 s, 3.2 MB/s\n"
"10485760 bytes (10 MB) copied, 3.56341 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.56908 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.53043 s, 3.0 MB/s\n"
"10485760 bytes (10 MB) copied, 3.57511 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.53672 s, 3.0 MB/s\n"
"10485760 bytes (10 MB) copied, 3.5433 s, 3.0 MB/s\n"
"10485760 bytes (10 MB) copied, 3.65474 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.63694 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.90122 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 3.88507 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 3.86135 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 3.84553 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 3.88871 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 3.94943 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 4.12731 s, 2.5 MB/s\n"
"10485760 bytes (10 MB) copied, 4.15106 s, 2.5 MB/s\n"
"10485760 bytes (10 MB) copied, 4.21601 s, 2.5 MB/s\n"
"10485760 bytes (10 MB) copied, 4.35004 s, 2.4 MB/s\n"
"10485760 bytes (10 MB) copied, 4.33387 s, 2.4 MB/s\n"
"10485760 bytes (10 MB) copied, 4.55434 s, 2.3 MB/s\n"
"10485760 bytes (10 MB) copied, 4.52283 s, 2.3 MB/s\n"
"10485760 bytes (10 MB) copied, 4.52682 s, 2.3 MB/s\n"
"10485760 bytes (10 MB) copied, 4.56176 s, 2.3 MB/s\n"
"10485760 bytes (10 MB) copied, 4.62727 s, 2.3 MB/s\n"
"10485760 bytes (10 MB) copied, 4.78958 s, 2.2 MB/s\n"
"10485760 bytes (10 MB) copied, 4.79772 s, 2.2 MB/s\n"
"10485760 bytes (10 MB) copied, 4.78004 s, 2.2 MB/s\n"
"10485760 bytes (10 MB) copied, 4.77994 s, 2.2 MB/s\n"
"10485760 bytes (10 MB) copied, 4.86114 s, 2.2 MB/s\n"
"10485760 bytes (10 MB) copied, 4.88062 s, 2.1 MB/s\n"
"\n"
"real    0m4.978s\n"
"user    0m0.112s\n"
"sys     0m1.544s"

#. Tag: para
#: tuning_storagescheduler.xml:309
#, no-c-format
msgid ""
"Note that each process completes in similar times. This is the <systemitem "
"class=\"resource\">CFQ</systemitem> scheduler meeting its "
"<literal>target_latency</literal> : Each process has fair access to storage."
msgstr ""
"上記では、それぞれのプロセスがほぼ同等の時間で終わっていることに注意してください。"
"ここでは <systemitem class=\"resource\">CFQ</systemitem> のスケジューラに従い、"
" <literal>target_latency</literal> の値に適合するように調整が図られています。"
"つまり、各プロセスはストレージに対して同じ程度のアクセス時間を与えられています。"

#. Tag: para
#: tuning_storagescheduler.xml:315
#, no-c-format
msgid ""
"Note that the earlier processes complete somewhat faster. This happens "
"because the start time of the processes is not identical. In a more "
"complicated example, it is possible to control for this."
msgstr ""
"なお、初めのうちは比較的高速に動作していることにも注意してください。これはプロセスの"
"起動タイミングが正確に一致していないためで、より複雑な例では、これを制御して"
"行ないます。"

#. Tag: para
#: tuning_storagescheduler.xml:320
#, no-c-format
msgid "This is what happens when low_latency is disabled:"
msgstr "low_latency を無効化すると、下記のようになります:"

#. Tag: screen
#: tuning_storagescheduler.xml:323
#, no-c-format
msgid ""
"&prompt.root;echo 0 &gt; /sys/block/sda/queue/iosched/low_latency\n"
"&prompt.root;time ./dd-test.sh\n"
"10485760 bytes (10 MB) copied, 0.813519 s, 12.9 MB/s\n"
"10485760 bytes (10 MB) copied, 0.788106 s, 13.3 MB/s\n"
"10485760 bytes (10 MB) copied, 0.800404 s, 13.1 MB/s\n"
"10485760 bytes (10 MB) copied, 0.816398 s, 12.8 MB/s\n"
"10485760 bytes (10 MB) copied, 0.959087 s, 10.9 MB/s\n"
"10485760 bytes (10 MB) copied, 1.09563 s, 9.6 MB/s\n"
"10485760 bytes (10 MB) copied, 1.18716 s, 8.8 MB/s\n"
"10485760 bytes (10 MB) copied, 1.27661 s, 8.2 MB/s\n"
"10485760 bytes (10 MB) copied, 1.46312 s, 7.2 MB/s\n"
"10485760 bytes (10 MB) copied, 1.55489 s, 6.7 MB/s\n"
"10485760 bytes (10 MB) copied, 1.64277 s, 6.4 MB/s\n"
"10485760 bytes (10 MB) copied, 1.78196 s, 5.9 MB/s\n"
"10485760 bytes (10 MB) copied, 1.87496 s, 5.6 MB/s\n"
"10485760 bytes (10 MB) copied, 1.9461 s, 5.4 MB/s\n"
"10485760 bytes (10 MB) copied, 2.08351 s, 5.0 MB/s\n"
"10485760 bytes (10 MB) copied, 2.28003 s, 4.6 MB/s\n"
"10485760 bytes (10 MB) copied, 2.42979 s, 4.3 MB/s\n"
"10485760 bytes (10 MB) copied, 2.54564 s, 4.1 MB/s\n"
"10485760 bytes (10 MB) copied, 2.6411 s, 4.0 MB/s\n"
"10485760 bytes (10 MB) copied, 2.75171 s, 3.8 MB/s\n"
"10485760 bytes (10 MB) copied, 2.86162 s, 3.7 MB/s\n"
"10485760 bytes (10 MB) copied, 2.98453 s, 3.5 MB/s\n"
"10485760 bytes (10 MB) copied, 3.13723 s, 3.3 MB/s\n"
"10485760 bytes (10 MB) copied, 3.36399 s, 3.1 MB/s\n"
"10485760 bytes (10 MB) copied, 3.60018 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.58151 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.67385 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.69471 s, 2.8 MB/s\n"
"10485760 bytes (10 MB) copied, 3.66658 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.81495 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 4.10172 s, 2.6 MB/s\n"
"10485760 bytes (10 MB) copied, 4.0966 s, 2.6 MB/s\n"
"\n"
"real    0m3.505s\n"
"user    0m0.160s\n"
"sys     0m1.516s"
msgstr ""
"&prompt.root;echo 0 &gt; /sys/block/sda/queue/iosched/low_latency\n"
"&prompt.root;time ./dd-test.sh\n"
"10485760 bytes (10 MB) copied, 0.813519 s, 12.9 MB/s\n"
"10485760 bytes (10 MB) copied, 0.788106 s, 13.3 MB/s\n"
"10485760 bytes (10 MB) copied, 0.800404 s, 13.1 MB/s\n"
"10485760 bytes (10 MB) copied, 0.816398 s, 12.8 MB/s\n"
"10485760 bytes (10 MB) copied, 0.959087 s, 10.9 MB/s\n"
"10485760 bytes (10 MB) copied, 1.09563 s, 9.6 MB/s\n"
"10485760 bytes (10 MB) copied, 1.18716 s, 8.8 MB/s\n"
"10485760 bytes (10 MB) copied, 1.27661 s, 8.2 MB/s\n"
"10485760 bytes (10 MB) copied, 1.46312 s, 7.2 MB/s\n"
"10485760 bytes (10 MB) copied, 1.55489 s, 6.7 MB/s\n"
"10485760 bytes (10 MB) copied, 1.64277 s, 6.4 MB/s\n"
"10485760 bytes (10 MB) copied, 1.78196 s, 5.9 MB/s\n"
"10485760 bytes (10 MB) copied, 1.87496 s, 5.6 MB/s\n"
"10485760 bytes (10 MB) copied, 1.9461 s, 5.4 MB/s\n"
"10485760 bytes (10 MB) copied, 2.08351 s, 5.0 MB/s\n"
"10485760 bytes (10 MB) copied, 2.28003 s, 4.6 MB/s\n"
"10485760 bytes (10 MB) copied, 2.42979 s, 4.3 MB/s\n"
"10485760 bytes (10 MB) copied, 2.54564 s, 4.1 MB/s\n"
"10485760 bytes (10 MB) copied, 2.6411 s, 4.0 MB/s\n"
"10485760 bytes (10 MB) copied, 2.75171 s, 3.8 MB/s\n"
"10485760 bytes (10 MB) copied, 2.86162 s, 3.7 MB/s\n"
"10485760 bytes (10 MB) copied, 2.98453 s, 3.5 MB/s\n"
"10485760 bytes (10 MB) copied, 3.13723 s, 3.3 MB/s\n"
"10485760 bytes (10 MB) copied, 3.36399 s, 3.1 MB/s\n"
"10485760 bytes (10 MB) copied, 3.60018 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.58151 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.67385 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.69471 s, 2.8 MB/s\n"
"10485760 bytes (10 MB) copied, 3.66658 s, 2.9 MB/s\n"
"10485760 bytes (10 MB) copied, 3.81495 s, 2.7 MB/s\n"
"10485760 bytes (10 MB) copied, 4.10172 s, 2.6 MB/s\n"
"10485760 bytes (10 MB) copied, 4.0966 s, 2.6 MB/s\n"
"\n"
"real    0m3.505s\n"
"user    0m0.160s\n"
"sys     0m1.516s"

#. Tag: para
#: tuning_storagescheduler.xml:361
#, no-c-format
msgid ""
"Note that the time processes take to complete is spread much wider as "
"processes are not getting fair access. Some processes complete faster and "
"exit, allowing the total workload to complete faster, and some processes "
"measure higher apparent I/O performance. It is also important to note that "
"this example may not behave similarly on all systems as the results depend "
"on the resources of the machine and the underlying storage."
msgstr ""
"上記では、各プロセスに対して公平な時間が割り当てられていないことから、処理にかかる"
"時間が大きくばらついていることに注意してください。プロセスによっては高速に動作して"
"終わっているものもありますので、これによって全体もより高速に処理できていることになり、"
"見かけ上のスループットも多角になっています。また、マシン側のリソース状況や接続されて"
"いるストレージの種類に依存して性能が決まるため、全てのシステムで同じような結果に"
"なるとは限らないことにも注意してください。"

#. Tag: para
#: tuning_storagescheduler.xml:370
#, no-c-format
msgid ""
"It is important to emphasize that neither tuning option is inherently better "
"than the other. Both are best in different circumstances and it is important "
"to understand the requirements of your workload and tune accordingly."
msgstr ""
"また、どの環境でも確実に性能を向上することのできるチューニングオプションというものも、"
"存在していないことに注意してください。状況によって最適なチューニングは異なりますし、"
"負荷ごとに要件も異なりますので、これによって設定内容も異なることになります。"

#. Tag: title
#: tuning_storagescheduler.xml:380
#, no-c-format
msgid "<systemitem class=\"resource\">NOOP</systemitem>"
msgstr "<systemitem class=\"resource\">NOOP</systemitem>"

#. Tag: para
#: tuning_storagescheduler.xml:381
#, no-c-format
msgid ""
"A trivial scheduler that only passes down the I/O that comes to it. Useful "
"for checking whether complex I/O scheduling decisions of other schedulers "
"are causing I/O performance regressions."
msgstr ""
"届いた I/O リクエストをそのまま流すだけの単純なスケジューラです。他のスケジューラ"
"との比較のために用意されていて、たとえばチューニングによって性能が悪化していない"
"ことを確認するために使用します。"

#. Tag: para
#: tuning_storagescheduler.xml:386
#, no-c-format
msgid ""
"This scheduler is recommended for setups with devices that do I/O scheduling "
"themselves, such as intelligent storage or in multipathing environments. If "
"you choose a more complicated scheduler on the host, the scheduler of the "
"host and the scheduler of the storage device compete with each other. This "
"can decrease performance. The storage device can usually determine best how "
"to schedule I/O."
msgstr ""
"このスケジューラは、デバイス側で I/O スケジューリングを実施するような、たとえば"
"インテリジェント型ストレージやマルチパス環境などでお勧めです。ホスト側でより複雑な"
"スケジューラを選択してしまうと、ホスト側とデバイス側のスケジューリングが競合して"
"しまい、性能が落ちてしまうことがあるからです。このようなストレージデバイスの場合は、"
"デバイス側で I/O のスケジュールを実施するのが適切です。"

#. Tag: para
#: tuning_storagescheduler.xml:394
#, no-c-format
msgid ""
"For similar reasons, this scheduler is also recommended for use within "
"virtual machines."
msgstr "同様の理由により、このスケジューラは仮想マシンにもお勧めです。"

#. Tag: para
#: tuning_storagescheduler.xml:398
#, no-c-format
msgid ""
"The <systemitem class=\"resource\">NOOP</systemitem> scheduler can be useful "
"for devices that do not depend on mechanical movement, like SSDs. Usually, "
"the <systemitem class=\"resource\">DEADLINE</systemitem> I/O scheduler is a "
"better choice for these devices. However, <systemitem class=\"resource"
"\">NOOP</systemitem> creates less overhead and thus can on certain workloads "
"increase performance."
msgstr ""
"また、 <systemitem class=\"resource\">NOOP</systemitem> スケジューラは、機械的な"
"動作のない、 SSD のようなデバイスに対しても便利な仕組みです。ただし SSD の場合、"
"通常は <systemitem class=\"resource\">DEADLINE</systemitem> I/O スケジューラの"
"ほうが適切です。しかしながら、 <systemitem class=\"resource\">NOOP</systemitem> "
"はオーバーヘッドの少ない仕組みであることから、特定の負荷に対しては性能を向上させる"
"ことになります。"

#. Tag: title
#: tuning_storagescheduler.xml:410
#, no-c-format
msgid "<systemitem class=\"resource\">DEADLINE</systemitem>"
msgstr "<systemitem class=\"resource\">DEADLINE</systemitem>"

#. Tag: para
#: tuning_storagescheduler.xml:411
#, no-c-format
msgid ""
"<systemitem class=\"resource\">DEADLINE</systemitem> is a latency-oriented I/"
"O scheduler. Each I/O request is assigned a deadline. Usually, requests are "
"stored in queues (read and write) sorted by sector numbers. The <systemitem "
"class=\"resource\">DEADLINE</systemitem> algorithm maintains two additional "
"queues (read and write) in which requests are sorted by deadline. As long as "
"no request has timed out, the <quote>sector</quote> queue is used. When "
"timeouts occur, requests from the <quote>deadline</quote> queue are served "
"until there are no more expired requests. Generally, the algorithm prefers "
"reads over writes."
msgstr ""
"<systemitem class=\"resource\">DEADLINE</systemitem> は遅延時間の削減を重視した"
"スケジューラです。それぞれの I/O リクエストには期限が設定されます。通常はセクタ"
"番号順に並べ替えられてキュー (読み込みおよび書き込み) 内に保存されますが、"
" <systemitem class=\"resource\">DEADLINE</systemitem> アルゴリズムでは期限順に"
"並べ替えられた 2 種類の追加キュー (読み込みおよび書き込み) を管理します。リクエスト"
"の期限が切れない限り、 <quote>セクタ順</quote> のキューを使用します。いったん期限"
"切れのものが発生すると、期限切れのリクエストがなくなるまで、 <quote>期限順</quote> "
"のキューを使用して処理を行なうようになります。また、一般的にアルゴリズムは書き込み"
"よりも読み込みを優先します。"

#. Tag: para
#: tuning_storagescheduler.xml:422
#, no-c-format
msgid ""
"This scheduler can provide a superior throughput over the <systemitem class="
"\"resource\">CFQ</systemitem> I/O scheduler in cases where several threads "
"read and write and fairness is not an issue. For example, for several "
"parallel readers from a SAN and for databases (especially when using "
"<quote>TCQ</quote> disks). The <systemitem class=\"resource\">DEADLINE</"
"systemitem> scheduler has the following tunable parameters:"
msgstr ""
"このスケジューラは、いくつかのスレッドが読み込みと書き込みを行なっているものの、"
"公平性を重視しないような環境で、 <systemitem class=\"resource\">CFQ</systemitem> "
"I/O スケジューラよりも高い性能を提供します。たとえば SAN とデータベースから読み込み"
"を行なっているプロセスがいくつか存在しているような場合 (特に <quote>TCQ</quote> "
"ディスクを使用しているような場合) がそれにあたります。 <systemitem class=\"resource\">"
"DEADLINE</systemitem> スケジューラには、下記のようなチューナブルパラメータが"
"用意されています:"

#. Tag: term
#: tuning_storagescheduler.xml:433
#, no-c-format
msgid ""
"<filename>/sys/block/<replaceable>&lt;device&gt;</replaceable>/queue/iosched/"
"writes_starved</filename>"
msgstr ""
"<filename>/sys/block/<replaceable>デバイス名</replaceable>/queue/iosched/"
"writes_starved</filename>"

#. Tag: para
#: tuning_storagescheduler.xml:436
#, no-c-format
msgid ""
"Controls how many reads can be sent to disk before it is possible to send "
"writes. A value of <literal>3</literal> means, that three read operations "
"are carried out for one write operation."
msgstr ""
"ディスクに対して書き込みを送信できるようになるまでに、どれだけの数の読み込みを"
"ディスクに送信できるようにするのかを制御します。たとえば <literal>3</literal> "
"という値であれば、 1 回の書き込み要求に対して 3 回の読み込み処理を行なうことに"
"なります。"

#. Tag: term
#: tuning_storagescheduler.xml:444
#, no-c-format
msgid ""
"<filename>/sys/block/<replaceable>&lt;device&gt;</replaceable>/queue/iosched/"
"read_expire</filename>"
msgstr ""
"<filename>/sys/block/<replaceable>デバイス名</replaceable>/queue/iosched/"
"read_expire</filename>"

#. Tag: para
#: tuning_storagescheduler.xml:447
#, no-c-format
msgid ""
"Sets the deadline (current time plus the read_expire value) for read "
"operations in milliseconds. The default is 500."
msgstr "ミリ秒単位で読み込み処理の期限 (現在時刻からの経過時間) を指定します。既定値は 500 です。"

#. Tag: term
#: tuning_storagescheduler.xml:454
#, no-c-format
msgid ""
"<filename>/sys/block/<replaceable>&lt;device&gt;</replaceable>/queue/iosched/"
"write_expire</filename>"
msgstr ""
"<filename>/sys/block/<replaceable>デバイス名</replaceable>/queue/iosched/"
"write_expire</filename>"

#. Tag: para
#: tuning_storagescheduler.xml:457
#, no-c-format
msgid ""
"<filename>/sys/block/<replaceable>&lt;device&gt;</replaceable>/queue/iosched/"
"read_expire</filename> Sets the deadline (current time plus the read_expire "
"value) for read operations in milliseconds. The default is 500."
msgstr ""
"<!-- NOTE: invalid explanation? it is for read_expire.. -->"
"ミリ秒単位で書き込み処理の期限 (現在時刻からの経過時間) を指定します。既定値は 500 です。"

#. Tag: title
#: tuning_storagescheduler.xml:468
#, no-c-format
msgid "I/O Barrier Tuning"
msgstr "I/O バリアのチューニング"

#. Tag: para
#: tuning_storagescheduler.xml:470
#, no-c-format
msgid ""
"<remark>sknorr, 2014-07-24: This might need updating to include Btrfs.</"
"remark> Most file systems (such as XFS, Ext3, or Ext4) send write barriers "
"to disk after fsync or during transaction commits. Write barriers enforce "
"proper ordering of writes, making volatile disk write caches safe to use (at "
"some performance penalty). If your disks are battery-backed in one way or "
"another, disabling barriers can safely improve performance."
msgstr ""
"<remark>sknorr, 2014-07-24: This might need updating to include Btrfs."
"</remark> ほとんどのファイルシステム (xfs, ext3, ext4 など) では、 fsync やトランザクション"
"のコミット時に、ディスクに対して書き込みバリアを送信します。書き込みバリアは書き込み"
"の順序を保証するための仕組みで、これによって揮発性のあるディスクの書き込みキャッシュ"
"を安全に使用できるようにしています (ただし、これによって少しの性能劣化があります) 。"
"お使いのディスクに何らかの方式によるバッテリーが搭載されている場合、バリアを無効化"
"しても、安全に性能を改善することができます。"

#. Tag: para
#: tuning_storagescheduler.xml:480
#, no-c-format
msgid ""
"Sending write barriers can be disabled using the <option>nobarrier</option> "
"mount option."
msgstr ""
"書き込みバリア送信の無効化は、 <option>nobarrier</option> マウントオプションで"
"行なうことができます。"

#. Tag: title
#: tuning_storagescheduler.xml:486
#, no-c-format
msgid "Disabling Barriers Can Lead to Data Loss"
msgstr "バリアの無効化によるデータ損失の危険性について"

#. Tag: para
#: tuning_storagescheduler.xml:487
#, no-c-format
msgid ""
"Disabling barriers when disks cannot guarantee caches are properly written "
"in case of power failure can lead to severe file system corruption and data "
"loss."
msgstr ""
"電源障害時にキャッシュからディスクへの書き込みが正しく保証されない環境でバリアを"
"無効化すると、ファイルシステムの破壊やデータ損失が発生することがあります。"

#. Tag: title
#: tuning_storagescheduler.xml:496
#, no-c-format
msgid "Enable blk-mq I/O Path for SCSI by Default"
msgstr "SCSI に対する既定での blk-mq I/O パスの有効化"

#. Tag: para
#: tuning_storagescheduler.xml:498
#, no-c-format
msgid ""
"Block multiqueue (blk-mq) is a multi-queue block I/O queuing mechanism. Blk-"
"mq uses per-cpu software queues to queue I/O requests. The software queues "
"are mapped to one or more hardware submission queues. Blk-mq significantly "
"reduces lock contention. In particular blk-mq improves performance for "
"devices that support a high number of input/output operations per second "
"(IOPS). Blk-mq is already the default for some devices, for example, NVM "
"Express devices."
msgstr ""
"ブロックマルチキュー (blk-mq) は複数のキューを利用するブロック I/O キューイング"
"機構です。 blk-mq では CPU ごとにソフトウエアキューを用意して、 I/O リクエストを"
"ため込みます。このソフトウエアキューは 1 つ以上のハードウエア発信キューに割り当て"
"られます。このような構造により、 blk-mq はロック競合を防ぐことができるようになって"
"います。 blk-mq では、 1 秒あたりに多くの I/O 操作 (IOPS) を行なうことのできる"
"デバイスで、性能改善に役立ちます。 blk-mq は NVM Express デバイスなど、いくつかの"
"デバイスに対しては既定で有効化されています。"

#. Tag: para
#: tuning_storagescheduler.xml:508
#, no-c-format
msgid ""
"Currently blk-mq has no I/O scheduling support (no CFQ, no deadline I/O "
"scheduler). This lack of I/O scheduling can cause significant performance "
"degradation when spinning disks are used. Therefore blk-mq is not enabled by "
"default for SCSI devices."
msgstr ""
"なお、現時点では blk-mq は I/O スケジューリングに対応していません (CFQ, deadline "
"のどちらも非対応です) 。この I/O スケジューリングの機能が欠けていることによって、"
"回転型のディスクを使用している場合、明確な性能劣化が派生します。そのため、 SCSI "
"デバイスに対しては、既定で blk-mq が無効化されるようになっています。"

#. Tag: para
#: tuning_storagescheduler.xml:515
#, no-c-format
msgid ""
"If you have fast SCSI devices (for example, SSDs) instead of SCSI hard disks "
"attached to your system, consider switching to blk-mq for SCSI. This is done "
"using the kernel command line option <literal>scsi_mod.use_blk_mq=1</"
"literal> ."
msgstr ""
"通常のハードディスクではなく、高速な SCSI デバイス (例: SSD) をお持ちの場合は、"
" SCSI に対して blk-mq への切り替えをご検討ください。切り替えは、カーネルのコマンド"
"ラインオプションに <literal>scsi_mod.use_blk_mq=1</literal> を追加することで"
"行なうことができます。"

