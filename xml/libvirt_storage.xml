<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter [
<!ENTITY % entities SYSTEM "generic-entities.ent">
%entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha-libvirt-storage">
  <title>高度なストレージ設定</title>
  <info>
    <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
      <dm:bugtracker/>
      <dm:translation>yes</dm:translation>
    </dm:docmanager>
  </info>
  <para>本章では、 &vmhost; の観点におけるストレージ関連の高度なトピックを説明しています。</para>
  <sect1 xml:id="sec-libvirt-storage-locking">
    <title><systemitem class="daemon">virtlockd</systemitem> を利用したディスクファイルやブロックデバイスのロック (施錠)</title>

    <para>ブロックデバイスやディスクファイルをロック (施錠) することで、これらのリソースを他の VM ゲストから書き込まれることがないように保護することができます。これにより、同一の &vmguest; が二重に起動されることを防ぐことができるほか、異なる仮想マシンに同じディスクが割り当てられたりすることがないようになります。これにより、仮想マシンのディスクイメージが、誤った設定によって破壊されてしまうのを防ぐことにもなります。</para>

    <para>ロック処理は <systemitem class="daemon">virtlockd</systemitem> と呼ばれるデーモンが取り扱います。 &libvirtd; デーモンとは個別に動作する仕組みであることから、 &libvirtd; がクラッシュしたり再起動したりしてしまったような場合でも、ロックを提供し続けることができます。さらに <systemitem class="daemon">virtlockd</systemitem> 自身の更新にも対応していて、自分自身で再起動を実施できるようになっています。これにより、 <systemitem class="daemon">virtlockd</systemitem> を更新しても、 &vmguest; を再起動する必要がありません。なお、 <systemitem class="daemon">virtlockd</systemitem> は &kvm;, &qemu;, &xen; にそれぞれ対応しています。</para>

    <sect2 xml:id="sec-libvirt-storage-locking-enable">
      <title>ロックの有効化</title>
      <para>仮想ディスクのロックは &productname; の既定では有効化されていません。有効化してシステムの起動時に自動的に開始されるようにするには、下記の手順を実施します:</para>
      <procedure>
        <step>
          <para><filename>/etc/libvirt/qemu.conf</filename> ファイルを編集して、下記を設定します:</para>
<screen>lock_manager = "lockd"</screen>
        </step>
        <step>
          <para>あとは過去のコマンドを実行して、 <systemitem class="daemon">virtlockd</systemitem> デーモンを開始します:</para>
<screen>&prompt.sudo;systemctl start virtlockd</screen>
        </step>
        <step>
          <para>&libvirtd; デーモンを再起動します:</para>
<screen>&prompt.sudo;systemctl restart libvirtd</screen>
        </step>
        <step>
          <para>システムの起動時に <systemitem class="daemon">virtlockd</systemitem> が自動的に開始されるように設定します:</para>
<screen>&prompt.sudo;systemctl enable virtlockd</screen>
        </step>
      </procedure>
    </sect2>

    <sect2 xml:id="sec-libvirt-storage-locking-configure">
      <title>ロックの設定</title>
      <para>既定では、 <systemitem class="daemon">virtlockd</systemitem> は &vmguest; に設定された全てのディスクを自動的にロックします。また、既定の設定では <quote>直接</quote> ロック領域を使用し、 VM ゲストの &lt;disk&gt; に書かれたデバイスに結びつけられたファイルに対して直接ロックを取得します。たとえば &vmguest; 内に下記のような設定が存在した場合、 <filename>/var/lib/libvirt/images/my-server/disk0.raw</filename> ファイルに対して <literal>flock(2)</literal> を直接実行して、ロックを獲得します:</para>
<screen>&lt;disk type='file' device='disk'&gt;
 &lt;driver name='qemu' type='raw'/&gt;
 &lt;source file='/var/lib/libvirt/images/my-server/disk0.raw'/&gt;
 &lt;target dev='vda' bus='virtio'/&gt;
&lt;/disk&gt;</screen>
      <para><systemitem class="daemon">virtlockd</systemitem> の設定は、設定ファイルである <filename>/etc/libvirt/qemu-lockd.conf</filename> を編集することで変更することができます。ここにはさらに詳しい情報の書かれたコメント (英語) が含まれています。なお、設定を変更した後は、それを反映させるために <systemitem class="daemon">virtlockd</systemitem> を再読み込みさせる必要があります:</para>
<screen>&prompt.sudo;systemctl reload virtlockd</screen>
      <!-- fs 2014-08-05: FIXME Check if tru &sle; 11 SP3
        <note>
        <title>Locking currently only available for all disks</title>
        <para>
        Currently, locking can only be activated globally, so that all virtual
        disks are locked. Support for locking selected disks is planned for future
        releases.
        </para>
        </note>
        <sect3 id="sec-libvirt-storage-locking-configure-noauto">
        <title>Manually managing locks</title>
        <para>
        As stated above, all virtual disks are locked by default. To
        restrict locking to selected disks, you need to turn off auto locking by
        setting
        </para>
        <screen>auto_disk_leases = 0</screen>
        <para>
        If auto locking is turned off you need to add &lt;lease> statements to
        the &lt;devices> section of the &vmguest;s XML definitions by editing
        them with the <command>virsh edit</command> command. A sample entry will
        look like the following example:
        </para>
        see https://www.redhat.com/archives/libvir-list/2013-April/msg01714.html
        <screen>TBD</screen>
        <para>
        Device leases
        When using a lock manager, it may be desirable to record device leases against a VM. The lock manager will ensure the VM won't start unless the leases can be acquired.
        ...
        <devices>
        ...
        <lease>
        <lockspace>somearea</lockspace>
        <key>somekey</key>
        <target path='/some/lease/path' offset='1024'/>
        </lease>
        ...
        </devices>
        ...
        lockspace
        This is an arbitrary string, identifying the lockspace within which the key is held. Lock managers may impose extra restrictions on the format, or length of the lockspace name.
        key
        This is an arbitrary string, uniquely identifying the lease to be acquired. Lock managers may impose extra restrictions on the format, or length of the key.
        target
        This is the fully qualified path of the file associated with the
        lockspace. The offset specifies where the lease is stored within the file. If
        the lock manager does not require a offset, just pass 0.
        </para>
        <important>
        <title>Starting &vmguest;s without locking</title>
        <para>
        If auto locking is disabled, <systemitem
        class="daemon">virtlockd</systemitem> automatically prevents all
        &vmguest;s that have no proper <quote>lease-configuration</quote> from
        being started. This ensures that only &vmguest;s with disks that are
        locked can be started.
        </para>
        <para>
        Disable this behavior by setting
        </para>
        <screen>require_lease_for_disks = 0</screen>
        </important>
        </sect3>
        -->
      <sect3 xml:id="sec-libvirt-storage-locking-configure-shared-fs">
        <title>間接ロック領域の有効化</title>
        <para><systemitem class="daemon">virtlockd</systemitem> の既定の設定では、 "直接" ロック領域を使用し、 VM ゲストの &lt;disk&gt; に書かれたデバイスに結びつけられたファイルに対して直接ロックを取得します。</para>
        <para>ディスクのファイルパスが全てのホストから直接アクセスできるものではない場合、 <systemitem class="daemon">virtlockd</systemitem> を設定して <quote>間接</quote> ロック領域を使用するように設定することができます。この場合、間接ロック領域ディレクトリ内に、ディスクファイルパスのハッシュファイルを作成します。このロックは、実際のディスクファイルパスの代用として使用され、保持されるようになります。間接ロック領域は、 <literal>fcntl()</literal> ロックに対応していないファイルシステムを使用する場合にも便利です。間接ロック領域は、 <option>file_lockspace_dir</option> 設定で指定します:</para>
<screen>file_lockspace_dir = "<replaceable>ロック領域のディレクトリ</replaceable>"</screen>
      </sect3>
      <sect3 xml:id="sec-libvirt-storage-locking-configure-lvm-iscsi">
        <title>LVM や iSCSI ボリュームでのロック有効化</title>
        <para>複数のホストで共有されている LVM や iSCSI ボリューム内に仮想ディスクが存在する場合、それらをロックするには、パス (既定で使用される方法) ではなく UUID で行う必要があります。それに加えてロック領域のディレクトリは、全てのホストからアクセスすることのできる共有の領域内に配置する必要があります。　<systemitem class="daemon">virtlockd</systemitem> の LVM/iSCSI におけるロックの設定は、下記のようになります:</para>
<screen>lvm_lockspace_dir = "<replaceable>ロック領域のディレクトリ</replaceable>"
iscsi_lockspace_dir = "<replaceable>ロック領域のディレクトリ</replaceable>"</screen>
      </sect3>
    </sect2>
  </sect1>
  <sect1 xml:id="sec-libvirt-storage-resize">
    <title>ゲストのブロックデバイスのオンラインサイズ変更</title>

    <para>状況によっては、ゲストシステムで使用されるブロックデバイスのサイズを変更し、サイズを大きくするか小さくする必要に迫られることがあります。たとえば元々割り当てていたサイズでは不足しているような場合には、サイズを増やす必要があります。ゲストに割り当てていたディスクが <emphasis>論理ボリューム</emphasis> 内に存在していれば、ゲストシステムを動作させた状態のままサイズを変更することができます。これはオフラインによるディスクサイズの変更 (<xref linkend="sec-guestfs-tools"/> 内で説明している <command>virt-resize</command> コマンドに関する説明をお読みください) とは異なり、サイズ変更時にもゲストを停止させる必要がありませんので、大きな利点になります。 &vmguest; のディスクサイズを変更するには、下記の手順を実施します:</para>

    <procedure>
      <title>ゲストディスクのオンラインサイズ変更</title>
      <step>
        <para>まずはゲストシステム内で、現在のサイズを確認します (下記では <filename>/dev/vda</filename> にディスクが配置されているものとします) 。</para>
<screen>&prompt.root;fdisk -l /dev/vda
Disk /dev/sda: 160.0 GB, 160041885696 bytes, 312581808 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes</screen>
      </step>
      <step>
        <para>ホスト側で、ゲストの <filename>/dev/vda</filename> を提供している論理ボリュームのサイズを変更します。ここではたとえば 200&nbsp;GB に変更します。</para>
<screen>&prompt.root;lvresize -L 200G /dev/mapper/vg00-home
Extending logical volume home to 200 GiB
Logical volume home successfully resized</screen>
      </step>
      <step>
        <para>ホスト側で、ゲストの <filename>/dev/mapper/vg00-home</filename> ディスクに対応するブロックデバイスのサイズを変更します。なお、下記の <replaceable>ドメイン_ID</replaceable> の箇所には、 <command>virsh list</command> で表示されるドメイン名 (仮想マシン名) を入力します。</para>
<screen>&prompt.root;virsh blockresize  --path /dev/vg00/home --size 200G <replaceable>ドメイン_ID</replaceable>
ブロックデバイス '/dev/vg00/home' の容量が変更されました</screen>
      </step>
      <step>
        <para>ゲスト側で、新しいディスクサイズが認識されていることを確認します。</para>
<screen>&prompt.root;fdisk -l /dev/vda
Disk /dev/sda: 200.0 GB, 200052357120 bytes, 390727260 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes</screen>
      </step>
    </procedure>
  </sect1>
  <sect1 xml:id="sec-libvirt-storage-share">
    <title>ホストとゲストの間でのディレクトリ共有 (ファイルシステムのパススルー)</title>

    <para>libvirt では、 &qemu; のファイルシステムパススルー (VirtFS とも呼ばれます) 機能を利用して、ホストとゲストの間でのディレクトリ共有を行うことができます。このようなディレクトリは複数の &vmguest; から同時にアクセスすることができるため、 &vmguest; 間でのファイル交換を行うこともできます。</para>

    <note>
      <title>Windows ゲストとファイルシステムのパススルーについて</title>
      <para>Windows ゲストには共有ディレクトリをマウントするためのデバイスドライバが提供されていないため、 &vmhost; と Windows ゲストとの間では、ファイルシステムのパススルー機能を利用してディレクトリの共有を行うことはできません。</para>
    </note>

    <para>&vmguest; に対してディレクトリを共有するには、下記の手順を実施します:</para>

    <procedure>
      <step>
        <para>&vmm; でゲストのコンソールを開いて、メニューから <menuchoice><guimenu>表示</guimenu> <guimenu>詳細</guimenu></menuchoice> を選択するか、もしくはツールバー内の <guimenu>仮想マシンの情報を表示</guimenu> を選択します。あとは <menuchoice> <guimenu>ハードウェアを追加</guimenu> <guimenu>ファイルシステム</guimenu> </menuchoice> を選択して、 <guimenu>ファイルシステム・パススルー</guimenu> を表示します。</para>
      </step>
      <step>
        <para><guimenu>ドライバー</guimenu> では、 <guimenu>Handle</guimenu> もしくは <guimenu>Path</guimenu> のいずれかを選択します。既定値は <guimenu>Path</guimenu> です。 <guimenu>モード</guimenu> ではセキュリティモデルを指定します。これは、ホスト内でのファイルパーミッションの設定方法を指定します。下記のいずれかを選択します:</para>
        <variablelist>
          <varlistentry>
            <term><guimenu>Passthrough</guimenu> (既定値)</term>
            <listitem>
              <para>ファイルシステム内のファイルを、クライアントユーザの権限で直接作成します。これは NFSv3 を利用している場合によく似ています。</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><guimenu>Squash</guimenu></term>
            <listitem>
              <para><guimenu>Passthrough</guimenu> と同様ですが、 <command>chown</command> などの特権操作の失敗については無視します。これは &kvm; が <systemitem class="username">root</systemitem> で動作していない場合に必要となります。</para>
            </listitem>
          </varlistentry>
          <varlistentry>
            <term><guimenu>Mapped</guimenu></term>
            <listitem>
              <para>ファイルサーバ側の権限 ( <literal>qemu.qemu</literal> ) でファイルを作成します。ユーザ権限とクライアント側の権限情報は、拡張属性内に保存します。このモデルは、ホストとゲストを完全に分離しておきたい場合にお勧めの設定です。</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </step>
      <step>
        <para>&vmhost; 内のディレクトリを <guimenu>ソースパス</guimenu> に指定します。なお、共有されたディレクトリをマウントする際には、 <guimenu>ターゲットパス</guimenu> に指定した名前を使用します。また、この文字列はタグとして使用するだけのものであり、 &vmguest; 内のパスを表すものではありません。</para>
      </step>
      <step>
        <para><!-- NOTE: not "Apply" but "Finish"? --><guimenu>完了</guimenu> を押して設定を適用します。 &vmguest; が動作中の場合は、設定を反映させるのにシャットダウンが必要となります (ゲストの再起動では不十分です) 。</para>
      </step>
      <step>
        <para>&vmguest; を起動します。共有されたディレクトリをマウントするには、下記のコマンドを実行します:</para>
<screen>&prompt.sudo;mount -t 9p -o trans=virtio,version=9p2000.L,rw <replaceable>タグ</replaceable> /<replaceable>マウントポイント</replaceable></screen>
        <para>共有されたディレクトリを恒久的にマウントしたい場合は、下記のような内容を <filename>/etc/fstab</filename> に追加します:</para>
<screen><replaceable>タグ</replaceable>   /<replaceable>マウントポイント</replaceable>    9p  trans=virtio,version=9p2000.L,rw    0   0</screen>
      </step>
    </procedure>
  </sect1>
  <sect1 xml:id="libvirt-storage-rbd">
    <title>&libvirt; を利用した RADOS ブロックデバイスの使用</title>

    <para>RADOS Block Devices (RBD) はデータを &ceph; クラスタに保存します。このブロックデバイスでは、スナップショットやレプリケーション、データの一貫性維持などを行うことができます。お使いの &libvirt; 管理下の &vmguest; から RBD を使用したい場合は、他のブロックデバイスと同様の手順を実施してください。</para>

    <para os="sles;sled">詳しくは &ses; の <citetitle>&admin;</citetitle> 内にある <citetitle>Using libvirt with Ceph</citetitle> (英語) の章をお読みください。 &ses; のドキュメンテーションは、 <link xlink:href="https://documentation.suse.com/ses/"/> で公開されています。</para>
  </sect1>
</chapter>
